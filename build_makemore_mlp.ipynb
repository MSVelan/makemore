{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aelie',\n",
       " 'darrellee',\n",
       " 'barbra',\n",
       " 'robsan',\n",
       " 'leovanni',\n",
       " 'haniyah',\n",
       " 'jhazzryn',\n",
       " 'tannistha',\n",
       " 'sujata',\n",
       " 'jairuz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"Files/processed_names.txt\", \"r\").read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30679"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aelie\n",
      "... ---> a\n",
      "..a ---> e\n",
      ".ae ---> l\n",
      "ael ---> i\n",
      "eli ---> e\n",
      "lie ---> .\n",
      "darrellee\n",
      "... ---> d\n",
      "..d ---> a\n",
      ".da ---> r\n",
      "dar ---> r\n",
      "arr ---> e\n",
      "rre ---> l\n",
      "rel ---> l\n",
      "ell ---> e\n",
      "lle ---> e\n",
      "lee ---> .\n",
      "barbra\n",
      "... ---> b\n",
      "..b ---> a\n",
      ".ba ---> r\n",
      "bar ---> b\n",
      "arb ---> r\n",
      "rbr ---> a\n",
      "bra ---> .\n",
      "robsan\n",
      "... ---> r\n",
      "..r ---> o\n",
      ".ro ---> b\n",
      "rob ---> s\n",
      "obs ---> a\n",
      "bsa ---> n\n",
      "san ---> .\n",
      "leovanni\n",
      "... ---> l\n",
      "..l ---> e\n",
      ".le ---> o\n",
      "leo ---> v\n",
      "eov ---> a\n",
      "ova ---> n\n",
      "van ---> n\n",
      "ann ---> i\n",
      "nni ---> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3  # context size for our neural network\n",
    "X, Y = [], []\n",
    "for w in words[:5]:  # This is an example for 5 words of the dataset only\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([39, 3]), torch.int64, torch.Size([39]), torch.int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to embed each of the 27 characters into 2 dimensional space first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.8412e-01,  1.5686e+00],\n",
       "        [ 2.2627e+00, -7.2440e-01],\n",
       "        [ 1.3581e+00,  9.4889e-01],\n",
       "        [-1.2194e+00, -9.3806e-01],\n",
       "        [ 1.1288e+00,  1.3496e+00],\n",
       "        [-2.3351e+00, -3.2683e-02],\n",
       "        [ 1.4459e+00, -1.4911e+00],\n",
       "        [ 2.6577e-01,  1.3736e-01],\n",
       "        [-1.0707e+00, -4.5795e-01],\n",
       "        [ 5.0178e-02, -8.3965e-01],\n",
       "        [ 4.7376e-01, -1.1218e+00],\n",
       "        [ 7.6823e-01, -2.5217e-01],\n",
       "        [ 3.1753e-01,  6.4720e-01],\n",
       "        [-2.1273e-03,  8.3613e-01],\n",
       "        [-1.1382e+00, -2.4189e-01],\n",
       "        [ 4.7322e-01, -4.2511e-01],\n",
       "        [ 2.5273e-01, -2.4777e-01],\n",
       "        [-1.1552e+00,  4.4664e-01],\n",
       "        [ 9.5101e-01,  3.8824e-01],\n",
       "        [ 1.0722e+00, -3.7033e-01],\n",
       "        [ 6.8207e-01,  1.0055e+00],\n",
       "        [ 1.6213e+00,  4.0314e-01],\n",
       "        [ 5.1092e-02,  6.1860e-01],\n",
       "        [ 4.6893e-01, -1.2941e+00],\n",
       "        [ 1.6941e+00,  1.4478e+00],\n",
       "        [ 1.8861e+00, -1.5764e-01],\n",
       "        [ 9.4811e-01, -1.4173e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3351, -0.0327])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Say to embed integer 5\n",
    "C[5]\n",
    "# Or \n",
    "# F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 3, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get embedding of all elements of X\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8841,  1.5686, -0.8841,  1.5686, -0.8841,  1.5686],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686,  2.2627, -0.7244],\n",
       "        [-0.8841,  1.5686,  2.2627, -0.7244, -2.3351, -0.0327],\n",
       "        [ 2.2627, -0.7244, -2.3351, -0.0327,  0.3175,  0.6472],\n",
       "        [-2.3351, -0.0327,  0.3175,  0.6472,  0.0502, -0.8396],\n",
       "        [ 0.3175,  0.6472,  0.0502, -0.8396, -2.3351, -0.0327],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686, -0.8841,  1.5686],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686,  1.1288,  1.3496],\n",
       "        [-0.8841,  1.5686,  1.1288,  1.3496,  2.2627, -0.7244],\n",
       "        [ 1.1288,  1.3496,  2.2627, -0.7244,  0.9510,  0.3882],\n",
       "        [ 2.2627, -0.7244,  0.9510,  0.3882,  0.9510,  0.3882],\n",
       "        [ 0.9510,  0.3882,  0.9510,  0.3882, -2.3351, -0.0327],\n",
       "        [ 0.9510,  0.3882, -2.3351, -0.0327,  0.3175,  0.6472],\n",
       "        [-2.3351, -0.0327,  0.3175,  0.6472,  0.3175,  0.6472],\n",
       "        [ 0.3175,  0.6472,  0.3175,  0.6472, -2.3351, -0.0327],\n",
       "        [ 0.3175,  0.6472, -2.3351, -0.0327, -2.3351, -0.0327],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686, -0.8841,  1.5686],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686,  1.3581,  0.9489],\n",
       "        [-0.8841,  1.5686,  1.3581,  0.9489,  2.2627, -0.7244],\n",
       "        [ 1.3581,  0.9489,  2.2627, -0.7244,  0.9510,  0.3882],\n",
       "        [ 2.2627, -0.7244,  0.9510,  0.3882,  1.3581,  0.9489],\n",
       "        [ 0.9510,  0.3882,  1.3581,  0.9489,  0.9510,  0.3882],\n",
       "        [ 1.3581,  0.9489,  0.9510,  0.3882,  2.2627, -0.7244],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686, -0.8841,  1.5686],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686,  0.9510,  0.3882],\n",
       "        [-0.8841,  1.5686,  0.9510,  0.3882,  0.4732, -0.4251],\n",
       "        [ 0.9510,  0.3882,  0.4732, -0.4251,  1.3581,  0.9489],\n",
       "        [ 0.4732, -0.4251,  1.3581,  0.9489,  1.0722, -0.3703],\n",
       "        [ 1.3581,  0.9489,  1.0722, -0.3703,  2.2627, -0.7244],\n",
       "        [ 1.0722, -0.3703,  2.2627, -0.7244, -1.1382, -0.2419],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686, -0.8841,  1.5686],\n",
       "        [-0.8841,  1.5686, -0.8841,  1.5686,  0.3175,  0.6472],\n",
       "        [-0.8841,  1.5686,  0.3175,  0.6472, -2.3351, -0.0327],\n",
       "        [ 0.3175,  0.6472, -2.3351, -0.0327,  0.4732, -0.4251],\n",
       "        [-2.3351, -0.0327,  0.4732, -0.4251,  0.0511,  0.6186],\n",
       "        [ 0.4732, -0.4251,  0.0511,  0.6186,  2.2627, -0.7244],\n",
       "        [ 0.0511,  0.6186,  2.2627, -0.7244, -1.1382, -0.2419],\n",
       "        [ 2.2627, -0.7244, -1.1382, -0.2419, -1.1382, -0.2419],\n",
       "        [-1.1382, -0.2419, -1.1382, -0.2419,  0.0502, -0.8396]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First layer of neurons\n",
    "W1 = torch.randn((6, 100))  # each example has shape (1, 3, 2) which has 6 elements and here we consider 100 neurons\n",
    "b1 = torch.randn((100,))\n",
    "# but first, we need to transform emb to have the shape (39, 6)\n",
    "emb.view(-1, 6)  # this is efficient than below options because it just manipulatest the storage of tensor\n",
    "# or\n",
    "# torch.cat((emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]), 1).shape\n",
    "# or \n",
    "# torch.cat(torch.unbind(emb, 1), 1).shape # this code generalizes to any block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.0782, -0.9959,  ...,  1.0000, -0.9652,  0.4611],\n",
       "        [-0.9117, -0.9996, -0.9134,  ...,  0.9428, -1.0000, -0.3235],\n",
       "        [ 0.9969,  0.6905, -0.9992,  ...,  0.9994,  0.7704,  0.9948],\n",
       "        ...,\n",
       "        [ 0.9991, -0.5258, -0.9598,  ...,  0.8469,  0.9357,  0.9896],\n",
       "        [ 0.8583,  0.9941,  0.9999,  ...,  0.9994,  1.0000,  0.9900],\n",
       "        [ 0.9994, -0.1813, -0.9960,  ..., -0.6858, -0.2254, -0.9449]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn((27,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 27])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 27])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3210e-07)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll = torch.tensor([probs[i, Y[i]] for i in torch.arange(Y.shape[0])]).log().mean().neg()\n",
    "# or alternatively\n",
    "nll = probs[torch.arange(Y.shape[0]), Y].log().mean().neg()  # nll denotes negative log likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarising the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3  # context size for our neural network\n",
    "X, Y = [], []\n",
    "for w in words:  \n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([229043, 3]), torch.Size([229043]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((6, 100), generator=g, requires_grad=True)\n",
    "b1 = torch.randn((100,), generator=g, requires_grad=True)\n",
    "W2 = torch.randn((100, 27), generator=g, requires_grad=True)\n",
    "b2 = torch.randn((27,), generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)  # total number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Loss: 19.220617294311523\n",
      "Iteration 2 , Loss: 16.93214225769043\n",
      "Iteration 3 , Loss: 15.696292877197266\n",
      "Iteration 4 , Loss: 14.784036636352539\n",
      "Iteration 5 , Loss: 13.97189712524414\n",
      "Iteration 6 , Loss: 13.240312576293945\n",
      "Iteration 7 , Loss: 12.584552764892578\n",
      "Iteration 8 , Loss: 12.00675106048584\n",
      "Iteration 9 , Loss: 11.51274585723877\n",
      "Iteration 10 , Loss: 11.109825134277344\n",
      "Iteration 11 , Loss: 10.781571388244629\n",
      "Iteration 12 , Loss: 10.492368698120117\n",
      "Iteration 13 , Loss: 10.224698066711426\n",
      "Iteration 14 , Loss: 9.972886085510254\n",
      "Iteration 15 , Loss: 9.73393726348877\n",
      "Iteration 16 , Loss: 9.505840301513672\n",
      "Iteration 17 , Loss: 9.287216186523438\n",
      "Iteration 18 , Loss: 9.077119827270508\n",
      "Iteration 19 , Loss: 8.874870300292969\n",
      "Iteration 20 , Loss: 8.67996597290039\n",
      "Iteration 21 , Loss: 8.492053031921387\n",
      "Iteration 22 , Loss: 8.310914039611816\n",
      "Iteration 23 , Loss: 8.136455535888672\n",
      "Iteration 24 , Loss: 7.968682765960693\n",
      "Iteration 25 , Loss: 7.807672500610352\n",
      "Iteration 26 , Loss: 7.653531074523926\n",
      "Iteration 27 , Loss: 7.506350994110107\n",
      "Iteration 28 , Loss: 7.366167068481445\n",
      "Iteration 29 , Loss: 7.2328948974609375\n",
      "Iteration 30 , Loss: 7.106298923492432\n",
      "Iteration 31 , Loss: 6.985995769500732\n",
      "Iteration 32 , Loss: 6.871494770050049\n",
      "Iteration 33 , Loss: 6.76227331161499\n",
      "Iteration 34 , Loss: 6.657825946807861\n",
      "Iteration 35 , Loss: 6.557706832885742\n",
      "Iteration 36 , Loss: 6.461535930633545\n",
      "Iteration 37 , Loss: 6.368995666503906\n",
      "Iteration 38 , Loss: 6.27981424331665\n",
      "Iteration 39 , Loss: 6.193763732910156\n",
      "Iteration 40 , Loss: 6.110646724700928\n",
      "Iteration 41 , Loss: 6.030290603637695\n",
      "Iteration 42 , Loss: 5.952544212341309\n",
      "Iteration 43 , Loss: 5.877274036407471\n",
      "Iteration 44 , Loss: 5.804358959197998\n",
      "Iteration 45 , Loss: 5.733686923980713\n",
      "Iteration 46 , Loss: 5.665154933929443\n",
      "Iteration 47 , Loss: 5.5986647605896\n",
      "Iteration 48 , Loss: 5.534126281738281\n",
      "Iteration 49 , Loss: 5.471450328826904\n",
      "Iteration 50 , Loss: 5.410558700561523\n",
      "Iteration 51 , Loss: 5.351377487182617\n",
      "Iteration 52 , Loss: 5.293838024139404\n",
      "Iteration 53 , Loss: 5.237884044647217\n",
      "Iteration 54 , Loss: 5.1834635734558105\n",
      "Iteration 55 , Loss: 5.130533218383789\n",
      "Iteration 56 , Loss: 5.079057693481445\n",
      "Iteration 57 , Loss: 5.029003620147705\n",
      "Iteration 58 , Loss: 4.980347156524658\n",
      "Iteration 59 , Loss: 4.933061599731445\n",
      "Iteration 60 , Loss: 4.887124538421631\n",
      "Iteration 61 , Loss: 4.842508316040039\n",
      "Iteration 62 , Loss: 4.799185752868652\n",
      "Iteration 63 , Loss: 4.757124900817871\n",
      "Iteration 64 , Loss: 4.7162885665893555\n",
      "Iteration 65 , Loss: 4.676638603210449\n",
      "Iteration 66 , Loss: 4.638131618499756\n",
      "Iteration 67 , Loss: 4.600724220275879\n",
      "Iteration 68 , Loss: 4.564372539520264\n",
      "Iteration 69 , Loss: 4.529034614562988\n",
      "Iteration 70 , Loss: 4.494670391082764\n",
      "Iteration 71 , Loss: 4.461241245269775\n",
      "Iteration 72 , Loss: 4.428709983825684\n",
      "Iteration 73 , Loss: 4.397044658660889\n",
      "Iteration 74 , Loss: 4.366214275360107\n",
      "Iteration 75 , Loss: 4.336186408996582\n",
      "Iteration 76 , Loss: 4.3069329261779785\n",
      "Iteration 77 , Loss: 4.278427600860596\n",
      "Iteration 78 , Loss: 4.250644207000732\n",
      "Iteration 79 , Loss: 4.2235589027404785\n",
      "Iteration 80 , Loss: 4.197146415710449\n",
      "Iteration 81 , Loss: 4.171387195587158\n",
      "Iteration 82 , Loss: 4.146261215209961\n",
      "Iteration 83 , Loss: 4.1217474937438965\n",
      "Iteration 84 , Loss: 4.097829818725586\n",
      "Iteration 85 , Loss: 4.074491500854492\n",
      "Iteration 86 , Loss: 4.051716327667236\n",
      "Iteration 87 , Loss: 4.0294904708862305\n",
      "Iteration 88 , Loss: 4.0077996253967285\n",
      "Iteration 89 , Loss: 3.986631155014038\n",
      "Iteration 90 , Loss: 3.9659714698791504\n",
      "Iteration 91 , Loss: 3.9458091259002686\n",
      "Iteration 92 , Loss: 3.9261322021484375\n",
      "Iteration 93 , Loss: 3.906928539276123\n",
      "Iteration 94 , Loss: 3.8881871700286865\n",
      "Iteration 95 , Loss: 3.86989688873291\n",
      "Iteration 96 , Loss: 3.8520472049713135\n",
      "Iteration 97 , Loss: 3.834625720977783\n",
      "Iteration 98 , Loss: 3.817622423171997\n",
      "Iteration 99 , Loss: 3.8010268211364746\n",
      "Iteration 100 , Loss: 3.784827709197998\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):    \n",
    "    # Forward pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Y)  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Loss: 3.769014596939087\n",
      "Iteration 2 , Loss: 3.753577709197998\n",
      "Iteration 3 , Loss: 3.738506555557251\n",
      "Iteration 4 , Loss: 3.7237908840179443\n",
      "Iteration 5 , Loss: 3.709420919418335\n",
      "Iteration 6 , Loss: 3.6953864097595215\n",
      "Iteration 7 , Loss: 3.681678533554077\n",
      "Iteration 8 , Loss: 3.6682872772216797\n",
      "Iteration 9 , Loss: 3.655202865600586\n",
      "Iteration 10 , Loss: 3.6424176692962646\n",
      "Iteration 11 , Loss: 3.6299211978912354\n",
      "Iteration 12 , Loss: 3.6177053451538086\n",
      "Iteration 13 , Loss: 3.6057612895965576\n",
      "Iteration 14 , Loss: 3.5940802097320557\n",
      "Iteration 15 , Loss: 3.5826542377471924\n",
      "Iteration 16 , Loss: 3.571474552154541\n",
      "Iteration 17 , Loss: 3.5605337619781494\n",
      "Iteration 18 , Loss: 3.549823045730591\n",
      "Iteration 19 , Loss: 3.5393362045288086\n",
      "Iteration 20 , Loss: 3.529064416885376\n",
      "Iteration 21 , Loss: 3.5190012454986572\n",
      "Iteration 22 , Loss: 3.5091400146484375\n",
      "Iteration 23 , Loss: 3.4994728565216064\n",
      "Iteration 24 , Loss: 3.489994525909424\n",
      "Iteration 25 , Loss: 3.4806978702545166\n",
      "Iteration 26 , Loss: 3.4715774059295654\n",
      "Iteration 27 , Loss: 3.4626271724700928\n",
      "Iteration 28 , Loss: 3.453840732574463\n",
      "Iteration 29 , Loss: 3.445213794708252\n",
      "Iteration 30 , Loss: 3.436741352081299\n",
      "Iteration 31 , Loss: 3.428417921066284\n",
      "Iteration 32 , Loss: 3.420239210128784\n",
      "Iteration 33 , Loss: 3.412200927734375\n",
      "Iteration 34 , Loss: 3.4042985439300537\n",
      "Iteration 35 , Loss: 3.3965275287628174\n",
      "Iteration 36 , Loss: 3.388885259628296\n",
      "Iteration 37 , Loss: 3.3813669681549072\n",
      "Iteration 38 , Loss: 3.373969554901123\n",
      "Iteration 39 , Loss: 3.3666903972625732\n",
      "Iteration 40 , Loss: 3.359524726867676\n",
      "Iteration 41 , Loss: 3.352471113204956\n",
      "Iteration 42 , Loss: 3.3455259799957275\n",
      "Iteration 43 , Loss: 3.338686466217041\n",
      "Iteration 44 , Loss: 3.3319501876831055\n",
      "Iteration 45 , Loss: 3.325314521789551\n",
      "Iteration 46 , Loss: 3.318777322769165\n",
      "Iteration 47 , Loss: 3.31233549118042\n",
      "Iteration 48 , Loss: 3.305988073348999\n",
      "Iteration 49 , Loss: 3.2997324466705322\n",
      "Iteration 50 , Loss: 3.2935667037963867\n",
      "Iteration 51 , Loss: 3.2874879837036133\n",
      "Iteration 52 , Loss: 3.281496047973633\n",
      "Iteration 53 , Loss: 3.275588035583496\n",
      "Iteration 54 , Loss: 3.269763231277466\n",
      "Iteration 55 , Loss: 3.264019250869751\n",
      "Iteration 56 , Loss: 3.258354663848877\n",
      "Iteration 57 , Loss: 3.2527682781219482\n",
      "Iteration 58 , Loss: 3.2472586631774902\n",
      "Iteration 59 , Loss: 3.2418246269226074\n",
      "Iteration 60 , Loss: 3.236464262008667\n",
      "Iteration 61 , Loss: 3.2311770915985107\n",
      "Iteration 62 , Loss: 3.225961685180664\n",
      "Iteration 63 , Loss: 3.2208168506622314\n",
      "Iteration 64 , Loss: 3.2157413959503174\n",
      "Iteration 65 , Loss: 3.2107346057891846\n",
      "Iteration 66 , Loss: 3.2057955265045166\n",
      "Iteration 67 , Loss: 3.200922727584839\n",
      "Iteration 68 , Loss: 3.196115493774414\n",
      "Iteration 69 , Loss: 3.191373348236084\n",
      "Iteration 70 , Loss: 3.186694383621216\n",
      "Iteration 71 , Loss: 3.1820790767669678\n",
      "Iteration 72 , Loss: 3.177525520324707\n",
      "Iteration 73 , Loss: 3.1730334758758545\n",
      "Iteration 74 , Loss: 3.1686017513275146\n",
      "Iteration 75 , Loss: 3.1642298698425293\n",
      "Iteration 76 , Loss: 3.159917116165161\n",
      "Iteration 77 , Loss: 3.1556622982025146\n",
      "Iteration 78 , Loss: 3.151465654373169\n",
      "Iteration 79 , Loss: 3.147325277328491\n",
      "Iteration 80 , Loss: 3.143240213394165\n",
      "Iteration 81 , Loss: 3.1392107009887695\n",
      "Iteration 82 , Loss: 3.1352360248565674\n",
      "Iteration 83 , Loss: 3.131314516067505\n",
      "Iteration 84 , Loss: 3.127445697784424\n",
      "Iteration 85 , Loss: 3.123629093170166\n",
      "Iteration 86 , Loss: 3.119863748550415\n",
      "Iteration 87 , Loss: 3.1161487102508545\n",
      "Iteration 88 , Loss: 3.112483263015747\n",
      "Iteration 89 , Loss: 3.1088669300079346\n",
      "Iteration 90 , Loss: 3.1052982807159424\n",
      "Iteration 91 , Loss: 3.1017768383026123\n",
      "Iteration 92 , Loss: 3.098301887512207\n",
      "Iteration 93 , Loss: 3.09487247467041\n",
      "Iteration 94 , Loss: 3.0914876461029053\n",
      "Iteration 95 , Loss: 3.088146924972534\n",
      "Iteration 96 , Loss: 3.0848493576049805\n",
      "Iteration 97 , Loss: 3.081594228744507\n",
      "Iteration 98 , Loss: 3.0783801078796387\n",
      "Iteration 99 , Loss: 3.075206756591797\n",
      "Iteration 100 , Loss: 3.0720741748809814\n"
     ]
    }
   ],
   "source": [
    "# Running it further\n",
    "for i in range(100):    \n",
    "    # Forward pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Y)  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is run twice and we find that the each iteration takes longer time, so we use minibatch instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting parameters\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((6, 100), generator=g, requires_grad=True)\n",
    "b1 = torch.randn((100,), generator=g, requires_grad=True)\n",
    "W2 = torch.randn((100, 27), generator=g, requires_grad=True)\n",
    "b2 = torch.randn((27,), generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre\n",
    "# lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Loss: 19.642507553100586\n",
      "Iteration 2 , Loss: 21.000919342041016\n",
      "Iteration 3 , Loss: 20.826698303222656\n",
      "Iteration 4 , Loss: 19.08496856689453\n",
      "Iteration 5 , Loss: 20.49187469482422\n",
      "Iteration 6 , Loss: 21.732582092285156\n",
      "Iteration 7 , Loss: 19.02778434753418\n",
      "Iteration 8 , Loss: 20.09446144104004\n",
      "Iteration 9 , Loss: 14.72089958190918\n",
      "Iteration 10 , Loss: 18.33893394470215\n",
      "Iteration 11 , Loss: 16.047670364379883\n",
      "Iteration 12 , Loss: 19.714208602905273\n",
      "Iteration 13 , Loss: 16.673229217529297\n",
      "Iteration 14 , Loss: 18.580760955810547\n",
      "Iteration 15 , Loss: 15.219694137573242\n",
      "Iteration 16 , Loss: 16.35300636291504\n",
      "Iteration 17 , Loss: 19.148942947387695\n",
      "Iteration 18 , Loss: 16.74610710144043\n",
      "Iteration 19 , Loss: 19.312585830688477\n",
      "Iteration 20 , Loss: 15.731391906738281\n",
      "Iteration 21 , Loss: 17.590639114379883\n",
      "Iteration 22 , Loss: 19.236602783203125\n",
      "Iteration 23 , Loss: 18.257795333862305\n",
      "Iteration 24 , Loss: 18.167966842651367\n",
      "Iteration 25 , Loss: 15.006281852722168\n",
      "Iteration 26 , Loss: 16.71932601928711\n",
      "Iteration 27 , Loss: 16.225465774536133\n",
      "Iteration 28 , Loss: 16.82681655883789\n",
      "Iteration 29 , Loss: 17.810483932495117\n",
      "Iteration 30 , Loss: 21.41204833984375\n",
      "Iteration 31 , Loss: 16.403797149658203\n",
      "Iteration 32 , Loss: 18.296295166015625\n",
      "Iteration 33 , Loss: 18.97820472717285\n",
      "Iteration 34 , Loss: 21.403034210205078\n",
      "Iteration 35 , Loss: 19.489439010620117\n",
      "Iteration 36 , Loss: 18.41265106201172\n",
      "Iteration 37 , Loss: 18.8591251373291\n",
      "Iteration 38 , Loss: 17.022974014282227\n",
      "Iteration 39 , Loss: 18.380996704101562\n",
      "Iteration 40 , Loss: 17.64480209350586\n",
      "Iteration 41 , Loss: 21.031728744506836\n",
      "Iteration 42 , Loss: 16.41646385192871\n",
      "Iteration 43 , Loss: 16.988204956054688\n",
      "Iteration 44 , Loss: 17.344139099121094\n",
      "Iteration 45 , Loss: 16.179107666015625\n",
      "Iteration 46 , Loss: 16.067415237426758\n",
      "Iteration 47 , Loss: 16.447107315063477\n",
      "Iteration 48 , Loss: 17.17490005493164\n",
      "Iteration 49 , Loss: 15.319499969482422\n",
      "Iteration 50 , Loss: 15.37563419342041\n",
      "Iteration 51 , Loss: 16.144969940185547\n",
      "Iteration 52 , Loss: 18.22643280029297\n",
      "Iteration 53 , Loss: 17.260316848754883\n",
      "Iteration 54 , Loss: 16.121383666992188\n",
      "Iteration 55 , Loss: 16.171472549438477\n",
      "Iteration 56 , Loss: 18.693695068359375\n",
      "Iteration 57 , Loss: 18.909780502319336\n",
      "Iteration 58 , Loss: 17.567419052124023\n",
      "Iteration 59 , Loss: 16.010656356811523\n",
      "Iteration 60 , Loss: 15.734888076782227\n",
      "Iteration 61 , Loss: 19.086881637573242\n",
      "Iteration 62 , Loss: 16.951692581176758\n",
      "Iteration 63 , Loss: 18.171682357788086\n",
      "Iteration 64 , Loss: 18.210426330566406\n",
      "Iteration 65 , Loss: 16.852054595947266\n",
      "Iteration 66 , Loss: 15.51490306854248\n",
      "Iteration 67 , Loss: 16.573253631591797\n",
      "Iteration 68 , Loss: 17.995868682861328\n",
      "Iteration 69 , Loss: 17.67071533203125\n",
      "Iteration 70 , Loss: 15.723641395568848\n",
      "Iteration 71 , Loss: 16.438968658447266\n",
      "Iteration 72 , Loss: 19.264888763427734\n",
      "Iteration 73 , Loss: 17.255125045776367\n",
      "Iteration 74 , Loss: 16.203397750854492\n",
      "Iteration 75 , Loss: 17.825889587402344\n",
      "Iteration 76 , Loss: 15.693217277526855\n",
      "Iteration 77 , Loss: 16.90998077392578\n",
      "Iteration 78 , Loss: 16.248313903808594\n",
      "Iteration 79 , Loss: 19.201162338256836\n",
      "Iteration 80 , Loss: 16.218713760375977\n",
      "Iteration 81 , Loss: 17.41673469543457\n",
      "Iteration 82 , Loss: 19.762027740478516\n",
      "Iteration 83 , Loss: 19.65338134765625\n",
      "Iteration 84 , Loss: 17.649738311767578\n",
      "Iteration 85 , Loss: 16.437849044799805\n",
      "Iteration 86 , Loss: 15.522627830505371\n",
      "Iteration 87 , Loss: 14.94058609008789\n",
      "Iteration 88 , Loss: 17.172222137451172\n",
      "Iteration 89 , Loss: 15.963078498840332\n",
      "Iteration 90 , Loss: 16.197927474975586\n",
      "Iteration 91 , Loss: 14.229016304016113\n",
      "Iteration 92 , Loss: 14.193044662475586\n",
      "Iteration 93 , Loss: 16.0494384765625\n",
      "Iteration 94 , Loss: 16.39349937438965\n",
      "Iteration 95 , Loss: 17.899927139282227\n",
      "Iteration 96 , Loss: 14.228414535522461\n",
      "Iteration 97 , Loss: 16.188901901245117\n",
      "Iteration 98 , Loss: 16.620243072509766\n",
      "Iteration 99 , Loss: 15.416704177856445\n",
      "Iteration 100 , Loss: 17.071144104003906\n",
      "Iteration 101 , Loss: 14.043652534484863\n",
      "Iteration 102 , Loss: 15.978853225708008\n",
      "Iteration 103 , Loss: 17.842193603515625\n",
      "Iteration 104 , Loss: 14.185848236083984\n",
      "Iteration 105 , Loss: 15.958681106567383\n",
      "Iteration 106 , Loss: 19.243026733398438\n",
      "Iteration 107 , Loss: 14.691105842590332\n",
      "Iteration 108 , Loss: 16.592973709106445\n",
      "Iteration 109 , Loss: 17.228500366210938\n",
      "Iteration 110 , Loss: 14.789690971374512\n",
      "Iteration 111 , Loss: 16.559450149536133\n",
      "Iteration 112 , Loss: 20.595813751220703\n",
      "Iteration 113 , Loss: 15.466225624084473\n",
      "Iteration 114 , Loss: 15.377756118774414\n",
      "Iteration 115 , Loss: 18.136516571044922\n",
      "Iteration 116 , Loss: 14.951685905456543\n",
      "Iteration 117 , Loss: 14.3353910446167\n",
      "Iteration 118 , Loss: 17.50818634033203\n",
      "Iteration 119 , Loss: 14.662662506103516\n",
      "Iteration 120 , Loss: 15.997453689575195\n",
      "Iteration 121 , Loss: 15.446091651916504\n",
      "Iteration 122 , Loss: 15.152135848999023\n",
      "Iteration 123 , Loss: 15.7432222366333\n",
      "Iteration 124 , Loss: 15.289806365966797\n",
      "Iteration 125 , Loss: 15.246391296386719\n",
      "Iteration 126 , Loss: 14.297677993774414\n",
      "Iteration 127 , Loss: 17.436073303222656\n",
      "Iteration 128 , Loss: 14.767343521118164\n",
      "Iteration 129 , Loss: 15.43604850769043\n",
      "Iteration 130 , Loss: 16.545289993286133\n",
      "Iteration 131 , Loss: 18.853445053100586\n",
      "Iteration 132 , Loss: 14.651859283447266\n",
      "Iteration 133 , Loss: 13.74402904510498\n",
      "Iteration 134 , Loss: 16.27515411376953\n",
      "Iteration 135 , Loss: 16.934898376464844\n",
      "Iteration 136 , Loss: 16.084749221801758\n",
      "Iteration 137 , Loss: 14.876670837402344\n",
      "Iteration 138 , Loss: 16.41181182861328\n",
      "Iteration 139 , Loss: 14.406856536865234\n",
      "Iteration 140 , Loss: 13.534740447998047\n",
      "Iteration 141 , Loss: 14.70689868927002\n",
      "Iteration 142 , Loss: 14.851619720458984\n",
      "Iteration 143 , Loss: 13.99262523651123\n",
      "Iteration 144 , Loss: 15.6925687789917\n",
      "Iteration 145 , Loss: 15.267702102661133\n",
      "Iteration 146 , Loss: 15.599236488342285\n",
      "Iteration 147 , Loss: 17.0562744140625\n",
      "Iteration 148 , Loss: 13.401262283325195\n",
      "Iteration 149 , Loss: 14.929789543151855\n",
      "Iteration 150 , Loss: 16.30417251586914\n",
      "Iteration 151 , Loss: 19.003700256347656\n",
      "Iteration 152 , Loss: 11.333742141723633\n",
      "Iteration 153 , Loss: 13.314854621887207\n",
      "Iteration 154 , Loss: 16.407981872558594\n",
      "Iteration 155 , Loss: 17.36909294128418\n",
      "Iteration 156 , Loss: 15.18409538269043\n",
      "Iteration 157 , Loss: 12.889778137207031\n",
      "Iteration 158 , Loss: 16.334611892700195\n",
      "Iteration 159 , Loss: 12.343256950378418\n",
      "Iteration 160 , Loss: 14.278900146484375\n",
      "Iteration 161 , Loss: 15.99775218963623\n",
      "Iteration 162 , Loss: 13.20650577545166\n",
      "Iteration 163 , Loss: 15.447774887084961\n",
      "Iteration 164 , Loss: 12.201976776123047\n",
      "Iteration 165 , Loss: 14.343402862548828\n",
      "Iteration 166 , Loss: 14.49134349822998\n",
      "Iteration 167 , Loss: 16.40211296081543\n",
      "Iteration 168 , Loss: 12.370747566223145\n",
      "Iteration 169 , Loss: 14.328484535217285\n",
      "Iteration 170 , Loss: 14.606919288635254\n",
      "Iteration 171 , Loss: 15.757756233215332\n",
      "Iteration 172 , Loss: 14.720805168151855\n",
      "Iteration 173 , Loss: 15.537327766418457\n",
      "Iteration 174 , Loss: 12.11386775970459\n",
      "Iteration 175 , Loss: 14.202743530273438\n",
      "Iteration 176 , Loss: 15.883354187011719\n",
      "Iteration 177 , Loss: 14.3149995803833\n",
      "Iteration 178 , Loss: 13.162483215332031\n",
      "Iteration 179 , Loss: 14.167166709899902\n",
      "Iteration 180 , Loss: 14.37126350402832\n",
      "Iteration 181 , Loss: 14.366397857666016\n",
      "Iteration 182 , Loss: 13.53929328918457\n",
      "Iteration 183 , Loss: 11.442604064941406\n",
      "Iteration 184 , Loss: 9.832174301147461\n",
      "Iteration 185 , Loss: 13.070408821105957\n",
      "Iteration 186 , Loss: 14.216192245483398\n",
      "Iteration 187 , Loss: 14.098273277282715\n",
      "Iteration 188 , Loss: 14.922201156616211\n",
      "Iteration 189 , Loss: 12.997588157653809\n",
      "Iteration 190 , Loss: 11.320854187011719\n",
      "Iteration 191 , Loss: 14.92645263671875\n",
      "Iteration 192 , Loss: 13.387443542480469\n",
      "Iteration 193 , Loss: 13.6185941696167\n",
      "Iteration 194 , Loss: 15.216442108154297\n",
      "Iteration 195 , Loss: 14.910934448242188\n",
      "Iteration 196 , Loss: 11.748405456542969\n",
      "Iteration 197 , Loss: 16.633275985717773\n",
      "Iteration 198 , Loss: 13.914308547973633\n",
      "Iteration 199 , Loss: 12.794808387756348\n",
      "Iteration 200 , Loss: 15.794341087341309\n",
      "Iteration 201 , Loss: 13.741796493530273\n",
      "Iteration 202 , Loss: 15.429051399230957\n",
      "Iteration 203 , Loss: 12.404642105102539\n",
      "Iteration 204 , Loss: 13.661849021911621\n",
      "Iteration 205 , Loss: 11.049422264099121\n",
      "Iteration 206 , Loss: 14.375340461730957\n",
      "Iteration 207 , Loss: 12.514751434326172\n",
      "Iteration 208 , Loss: 13.64051628112793\n",
      "Iteration 209 , Loss: 13.19051456451416\n",
      "Iteration 210 , Loss: 13.223199844360352\n",
      "Iteration 211 , Loss: 14.545719146728516\n",
      "Iteration 212 , Loss: 12.320199012756348\n",
      "Iteration 213 , Loss: 16.847230911254883\n",
      "Iteration 214 , Loss: 17.060623168945312\n",
      "Iteration 215 , Loss: 14.500419616699219\n",
      "Iteration 216 , Loss: 12.620676040649414\n",
      "Iteration 217 , Loss: 11.966415405273438\n",
      "Iteration 218 , Loss: 15.626818656921387\n",
      "Iteration 219 , Loss: 13.033897399902344\n",
      "Iteration 220 , Loss: 11.123634338378906\n",
      "Iteration 221 , Loss: 13.751591682434082\n",
      "Iteration 222 , Loss: 12.61659049987793\n",
      "Iteration 223 , Loss: 12.907310485839844\n",
      "Iteration 224 , Loss: 13.152316093444824\n",
      "Iteration 225 , Loss: 12.977479934692383\n",
      "Iteration 226 , Loss: 13.584745407104492\n",
      "Iteration 227 , Loss: 12.750682830810547\n",
      "Iteration 228 , Loss: 15.359281539916992\n",
      "Iteration 229 , Loss: 14.069376945495605\n",
      "Iteration 230 , Loss: 15.267627716064453\n",
      "Iteration 231 , Loss: 12.539188385009766\n",
      "Iteration 232 , Loss: 13.239251136779785\n",
      "Iteration 233 , Loss: 11.163354873657227\n",
      "Iteration 234 , Loss: 13.728837966918945\n",
      "Iteration 235 , Loss: 11.255467414855957\n",
      "Iteration 236 , Loss: 12.717026710510254\n",
      "Iteration 237 , Loss: 12.271824836730957\n",
      "Iteration 238 , Loss: 11.068790435791016\n",
      "Iteration 239 , Loss: 11.641315460205078\n",
      "Iteration 240 , Loss: 12.341805458068848\n",
      "Iteration 241 , Loss: 12.156651496887207\n",
      "Iteration 242 , Loss: 13.207537651062012\n",
      "Iteration 243 , Loss: 13.30001449584961\n",
      "Iteration 244 , Loss: 11.562178611755371\n",
      "Iteration 245 , Loss: 11.389564514160156\n",
      "Iteration 246 , Loss: 13.956049919128418\n",
      "Iteration 247 , Loss: 12.31071662902832\n",
      "Iteration 248 , Loss: 11.209111213684082\n",
      "Iteration 249 , Loss: 11.424747467041016\n",
      "Iteration 250 , Loss: 13.651473999023438\n",
      "Iteration 251 , Loss: 11.46831226348877\n",
      "Iteration 252 , Loss: 13.046725273132324\n",
      "Iteration 253 , Loss: 12.16877269744873\n",
      "Iteration 254 , Loss: 12.763528823852539\n",
      "Iteration 255 , Loss: 15.462087631225586\n",
      "Iteration 256 , Loss: 13.169672012329102\n",
      "Iteration 257 , Loss: 8.431109428405762\n",
      "Iteration 258 , Loss: 10.721933364868164\n",
      "Iteration 259 , Loss: 12.176345825195312\n",
      "Iteration 260 , Loss: 10.7133207321167\n",
      "Iteration 261 , Loss: 11.462471008300781\n",
      "Iteration 262 , Loss: 13.019290924072266\n",
      "Iteration 263 , Loss: 9.873115539550781\n",
      "Iteration 264 , Loss: 10.140063285827637\n",
      "Iteration 265 , Loss: 11.666824340820312\n",
      "Iteration 266 , Loss: 9.796998023986816\n",
      "Iteration 267 , Loss: 12.743514060974121\n",
      "Iteration 268 , Loss: 10.693339347839355\n",
      "Iteration 269 , Loss: 14.46713638305664\n",
      "Iteration 270 , Loss: 9.607580184936523\n",
      "Iteration 271 , Loss: 10.354639053344727\n",
      "Iteration 272 , Loss: 12.614063262939453\n",
      "Iteration 273 , Loss: 9.12226390838623\n",
      "Iteration 274 , Loss: 11.182609558105469\n",
      "Iteration 275 , Loss: 8.35865306854248\n",
      "Iteration 276 , Loss: 9.971832275390625\n",
      "Iteration 277 , Loss: 11.284802436828613\n",
      "Iteration 278 , Loss: 11.390129089355469\n",
      "Iteration 279 , Loss: 11.970142364501953\n",
      "Iteration 280 , Loss: 12.066009521484375\n",
      "Iteration 281 , Loss: 15.168899536132812\n",
      "Iteration 282 , Loss: 12.248772621154785\n",
      "Iteration 283 , Loss: 10.789705276489258\n",
      "Iteration 284 , Loss: 11.208507537841797\n",
      "Iteration 285 , Loss: 10.859240531921387\n",
      "Iteration 286 , Loss: 11.249116897583008\n",
      "Iteration 287 , Loss: 10.694122314453125\n",
      "Iteration 288 , Loss: 12.04391098022461\n",
      "Iteration 289 , Loss: 12.066328048706055\n",
      "Iteration 290 , Loss: 13.737041473388672\n",
      "Iteration 291 , Loss: 10.963268280029297\n",
      "Iteration 292 , Loss: 8.95407485961914\n",
      "Iteration 293 , Loss: 12.838489532470703\n",
      "Iteration 294 , Loss: 10.445181846618652\n",
      "Iteration 295 , Loss: 9.690651893615723\n",
      "Iteration 296 , Loss: 11.553462028503418\n",
      "Iteration 297 , Loss: 11.602540016174316\n",
      "Iteration 298 , Loss: 8.721653938293457\n",
      "Iteration 299 , Loss: 11.663679122924805\n",
      "Iteration 300 , Loss: 13.041747093200684\n",
      "Iteration 301 , Loss: 9.833621978759766\n",
      "Iteration 302 , Loss: 10.530555725097656\n",
      "Iteration 303 , Loss: 11.687779426574707\n",
      "Iteration 304 , Loss: 9.68761157989502\n",
      "Iteration 305 , Loss: 12.453436851501465\n",
      "Iteration 306 , Loss: 11.98730182647705\n",
      "Iteration 307 , Loss: 13.024191856384277\n",
      "Iteration 308 , Loss: 10.457538604736328\n",
      "Iteration 309 , Loss: 9.821416854858398\n",
      "Iteration 310 , Loss: 12.909225463867188\n",
      "Iteration 311 , Loss: 10.4782133102417\n",
      "Iteration 312 , Loss: 8.654216766357422\n",
      "Iteration 313 , Loss: 10.001428604125977\n",
      "Iteration 314 , Loss: 10.260868072509766\n",
      "Iteration 315 , Loss: 10.429959297180176\n",
      "Iteration 316 , Loss: 10.988238334655762\n",
      "Iteration 317 , Loss: 11.252643585205078\n",
      "Iteration 318 , Loss: 9.459321975708008\n",
      "Iteration 319 , Loss: 13.015168190002441\n",
      "Iteration 320 , Loss: 11.51636791229248\n",
      "Iteration 321 , Loss: 9.651164054870605\n",
      "Iteration 322 , Loss: 10.462201118469238\n",
      "Iteration 323 , Loss: 11.266610145568848\n",
      "Iteration 324 , Loss: 10.912603378295898\n",
      "Iteration 325 , Loss: 10.308843612670898\n",
      "Iteration 326 , Loss: 9.5176420211792\n",
      "Iteration 327 , Loss: 11.173652648925781\n",
      "Iteration 328 , Loss: 9.30455207824707\n",
      "Iteration 329 , Loss: 10.102823257446289\n",
      "Iteration 330 , Loss: 10.474997520446777\n",
      "Iteration 331 , Loss: 8.78493595123291\n",
      "Iteration 332 , Loss: 12.514049530029297\n",
      "Iteration 333 , Loss: 9.520608901977539\n",
      "Iteration 334 , Loss: 9.131072044372559\n",
      "Iteration 335 , Loss: 9.081561088562012\n",
      "Iteration 336 , Loss: 9.225774765014648\n",
      "Iteration 337 , Loss: 9.017647743225098\n",
      "Iteration 338 , Loss: 8.966350555419922\n",
      "Iteration 339 , Loss: 11.746113777160645\n",
      "Iteration 340 , Loss: 12.193073272705078\n",
      "Iteration 341 , Loss: 8.149979591369629\n",
      "Iteration 342 , Loss: 9.338143348693848\n",
      "Iteration 343 , Loss: 11.011590957641602\n",
      "Iteration 344 , Loss: 9.721382141113281\n",
      "Iteration 345 , Loss: 8.184606552124023\n",
      "Iteration 346 , Loss: 8.662181854248047\n",
      "Iteration 347 , Loss: 11.083980560302734\n",
      "Iteration 348 , Loss: 10.167435646057129\n",
      "Iteration 349 , Loss: 9.724685668945312\n",
      "Iteration 350 , Loss: 10.556693077087402\n",
      "Iteration 351 , Loss: 7.832629680633545\n",
      "Iteration 352 , Loss: 9.715771675109863\n",
      "Iteration 353 , Loss: 10.685478210449219\n",
      "Iteration 354 , Loss: 7.147418975830078\n",
      "Iteration 355 , Loss: 8.932069778442383\n",
      "Iteration 356 , Loss: 8.303227424621582\n",
      "Iteration 357 , Loss: 9.053070068359375\n",
      "Iteration 358 , Loss: 8.99764633178711\n",
      "Iteration 359 , Loss: 10.975906372070312\n",
      "Iteration 360 , Loss: 10.43004322052002\n",
      "Iteration 361 , Loss: 9.809228897094727\n",
      "Iteration 362 , Loss: 7.84421443939209\n",
      "Iteration 363 , Loss: 9.981069564819336\n",
      "Iteration 364 , Loss: 9.58803653717041\n",
      "Iteration 365 , Loss: 10.745121002197266\n",
      "Iteration 366 , Loss: 11.055858612060547\n",
      "Iteration 367 , Loss: 7.899448871612549\n",
      "Iteration 368 , Loss: 10.861034393310547\n",
      "Iteration 369 , Loss: 7.19020414352417\n",
      "Iteration 370 , Loss: 9.618006706237793\n",
      "Iteration 371 , Loss: 9.99727725982666\n",
      "Iteration 372 , Loss: 8.856829643249512\n",
      "Iteration 373 , Loss: 9.228887557983398\n",
      "Iteration 374 , Loss: 10.3934326171875\n",
      "Iteration 375 , Loss: 8.837740898132324\n",
      "Iteration 376 , Loss: 9.825671195983887\n",
      "Iteration 377 , Loss: 8.1889009475708\n",
      "Iteration 378 , Loss: 9.392387390136719\n",
      "Iteration 379 , Loss: 9.229588508605957\n",
      "Iteration 380 , Loss: 9.299442291259766\n",
      "Iteration 381 , Loss: 8.985779762268066\n",
      "Iteration 382 , Loss: 9.273794174194336\n",
      "Iteration 383 , Loss: 9.761083602905273\n",
      "Iteration 384 , Loss: 8.86081314086914\n",
      "Iteration 385 , Loss: 6.431307792663574\n",
      "Iteration 386 , Loss: 8.935712814331055\n",
      "Iteration 387 , Loss: 7.835538387298584\n",
      "Iteration 388 , Loss: 7.583600997924805\n",
      "Iteration 389 , Loss: 7.464116096496582\n",
      "Iteration 390 , Loss: 9.767152786254883\n",
      "Iteration 391 , Loss: 9.084166526794434\n",
      "Iteration 392 , Loss: 7.811217784881592\n",
      "Iteration 393 , Loss: 8.227537155151367\n",
      "Iteration 394 , Loss: 6.903962135314941\n",
      "Iteration 395 , Loss: 8.858237266540527\n",
      "Iteration 396 , Loss: 9.148090362548828\n",
      "Iteration 397 , Loss: 7.948978424072266\n",
      "Iteration 398 , Loss: 9.725488662719727\n",
      "Iteration 399 , Loss: 8.483654022216797\n",
      "Iteration 400 , Loss: 6.601507186889648\n",
      "Iteration 401 , Loss: 8.267117500305176\n",
      "Iteration 402 , Loss: 7.752645969390869\n",
      "Iteration 403 , Loss: 8.861610412597656\n",
      "Iteration 404 , Loss: 7.661533832550049\n",
      "Iteration 405 , Loss: 7.709624767303467\n",
      "Iteration 406 , Loss: 7.215022087097168\n",
      "Iteration 407 , Loss: 8.941856384277344\n",
      "Iteration 408 , Loss: 8.338916778564453\n",
      "Iteration 409 , Loss: 9.406394004821777\n",
      "Iteration 410 , Loss: 8.31179428100586\n",
      "Iteration 411 , Loss: 8.120537757873535\n",
      "Iteration 412 , Loss: 7.317699909210205\n",
      "Iteration 413 , Loss: 7.506817817687988\n",
      "Iteration 414 , Loss: 10.586230278015137\n",
      "Iteration 415 , Loss: 7.428254127502441\n",
      "Iteration 416 , Loss: 6.087283611297607\n",
      "Iteration 417 , Loss: 7.609849452972412\n",
      "Iteration 418 , Loss: 9.605245590209961\n",
      "Iteration 419 , Loss: 6.871082305908203\n",
      "Iteration 420 , Loss: 9.195598602294922\n",
      "Iteration 421 , Loss: 9.567696571350098\n",
      "Iteration 422 , Loss: 6.178491592407227\n",
      "Iteration 423 , Loss: 8.249446868896484\n",
      "Iteration 424 , Loss: 7.911073684692383\n",
      "Iteration 425 , Loss: 7.1006083488464355\n",
      "Iteration 426 , Loss: 6.339291095733643\n",
      "Iteration 427 , Loss: 7.8441853523254395\n",
      "Iteration 428 , Loss: 9.09703540802002\n",
      "Iteration 429 , Loss: 7.910703182220459\n",
      "Iteration 430 , Loss: 7.51688814163208\n",
      "Iteration 431 , Loss: 5.928635597229004\n",
      "Iteration 432 , Loss: 5.650252342224121\n",
      "Iteration 433 , Loss: 9.471909523010254\n",
      "Iteration 434 , Loss: 8.944851875305176\n",
      "Iteration 435 , Loss: 5.656926155090332\n",
      "Iteration 436 , Loss: 8.336735725402832\n",
      "Iteration 437 , Loss: 7.4576544761657715\n",
      "Iteration 438 , Loss: 7.1663689613342285\n",
      "Iteration 439 , Loss: 6.949064254760742\n",
      "Iteration 440 , Loss: 6.626528263092041\n",
      "Iteration 441 , Loss: 7.480406284332275\n",
      "Iteration 442 , Loss: 6.673680782318115\n",
      "Iteration 443 , Loss: 6.2167463302612305\n",
      "Iteration 444 , Loss: 7.050140857696533\n",
      "Iteration 445 , Loss: 5.425261497497559\n",
      "Iteration 446 , Loss: 5.393594741821289\n",
      "Iteration 447 , Loss: 7.187561511993408\n",
      "Iteration 448 , Loss: 7.072659969329834\n",
      "Iteration 449 , Loss: 5.525222301483154\n",
      "Iteration 450 , Loss: 5.609210014343262\n",
      "Iteration 451 , Loss: 7.812928676605225\n",
      "Iteration 452 , Loss: 5.530948638916016\n",
      "Iteration 453 , Loss: 8.03209114074707\n",
      "Iteration 454 , Loss: 5.537726402282715\n",
      "Iteration 455 , Loss: 5.983917236328125\n",
      "Iteration 456 , Loss: 8.727027893066406\n",
      "Iteration 457 , Loss: 5.821505546569824\n",
      "Iteration 458 , Loss: 5.399451732635498\n",
      "Iteration 459 , Loss: 7.019783020019531\n",
      "Iteration 460 , Loss: 7.105269432067871\n",
      "Iteration 461 , Loss: 6.952688217163086\n",
      "Iteration 462 , Loss: 6.614801406860352\n",
      "Iteration 463 , Loss: 6.6245036125183105\n",
      "Iteration 464 , Loss: 6.4036455154418945\n",
      "Iteration 465 , Loss: 4.941715240478516\n",
      "Iteration 466 , Loss: 7.699610233306885\n",
      "Iteration 467 , Loss: 8.317403793334961\n",
      "Iteration 468 , Loss: 7.418652057647705\n",
      "Iteration 469 , Loss: 5.232161045074463\n",
      "Iteration 470 , Loss: 6.767234802246094\n",
      "Iteration 471 , Loss: 7.757497310638428\n",
      "Iteration 472 , Loss: 5.797468662261963\n",
      "Iteration 473 , Loss: 7.138643741607666\n",
      "Iteration 474 , Loss: 7.298826217651367\n",
      "Iteration 475 , Loss: 4.604702949523926\n",
      "Iteration 476 , Loss: 5.60017204284668\n",
      "Iteration 477 , Loss: 3.596970319747925\n",
      "Iteration 478 , Loss: 7.004043102264404\n",
      "Iteration 479 , Loss: 6.322570323944092\n",
      "Iteration 480 , Loss: 8.653692245483398\n",
      "Iteration 481 , Loss: 5.962747573852539\n",
      "Iteration 482 , Loss: 6.841705322265625\n",
      "Iteration 483 , Loss: 6.300673484802246\n",
      "Iteration 484 , Loss: 5.664493083953857\n",
      "Iteration 485 , Loss: 6.528255462646484\n",
      "Iteration 486 , Loss: 5.8381733894348145\n",
      "Iteration 487 , Loss: 5.126960754394531\n",
      "Iteration 488 , Loss: 5.7864837646484375\n",
      "Iteration 489 , Loss: 5.746822357177734\n",
      "Iteration 490 , Loss: 5.281944274902344\n",
      "Iteration 491 , Loss: 5.7317705154418945\n",
      "Iteration 492 , Loss: 7.017173767089844\n",
      "Iteration 493 , Loss: 5.382593631744385\n",
      "Iteration 494 , Loss: 6.064266204833984\n",
      "Iteration 495 , Loss: 5.324375629425049\n",
      "Iteration 496 , Loss: 6.327185153961182\n",
      "Iteration 497 , Loss: 6.944099426269531\n",
      "Iteration 498 , Loss: 6.4652252197265625\n",
      "Iteration 499 , Loss: 5.591130256652832\n",
      "Iteration 500 , Loss: 6.34324836730957\n",
      "Iteration 501 , Loss: 5.73225736618042\n",
      "Iteration 502 , Loss: 6.322019100189209\n",
      "Iteration 503 , Loss: 4.227355003356934\n",
      "Iteration 504 , Loss: 4.839850425720215\n",
      "Iteration 505 , Loss: 5.074942111968994\n",
      "Iteration 506 , Loss: 5.416754722595215\n",
      "Iteration 507 , Loss: 4.4731950759887695\n",
      "Iteration 508 , Loss: 6.917839527130127\n",
      "Iteration 509 , Loss: 5.503964424133301\n",
      "Iteration 510 , Loss: 4.455605506896973\n",
      "Iteration 511 , Loss: 5.501081943511963\n",
      "Iteration 512 , Loss: 6.079259395599365\n",
      "Iteration 513 , Loss: 7.956696510314941\n",
      "Iteration 514 , Loss: 4.3856120109558105\n",
      "Iteration 515 , Loss: 5.690952301025391\n",
      "Iteration 516 , Loss: 4.919677257537842\n",
      "Iteration 517 , Loss: 5.983119487762451\n",
      "Iteration 518 , Loss: 5.326937198638916\n",
      "Iteration 519 , Loss: 5.602520942687988\n",
      "Iteration 520 , Loss: 5.039742469787598\n",
      "Iteration 521 , Loss: 4.783323764801025\n",
      "Iteration 522 , Loss: 4.926712989807129\n",
      "Iteration 523 , Loss: 5.853359222412109\n",
      "Iteration 524 , Loss: 4.104112148284912\n",
      "Iteration 525 , Loss: 6.093919277191162\n",
      "Iteration 526 , Loss: 5.545867919921875\n",
      "Iteration 527 , Loss: 4.955832481384277\n",
      "Iteration 528 , Loss: 4.070733070373535\n",
      "Iteration 529 , Loss: 4.1113409996032715\n",
      "Iteration 530 , Loss: 5.3524065017700195\n",
      "Iteration 531 , Loss: 5.324635982513428\n",
      "Iteration 532 , Loss: 4.85658073425293\n",
      "Iteration 533 , Loss: 5.310682773590088\n",
      "Iteration 534 , Loss: 4.475528717041016\n",
      "Iteration 535 , Loss: 4.787018775939941\n",
      "Iteration 536 , Loss: 4.092006683349609\n",
      "Iteration 537 , Loss: 5.200101375579834\n",
      "Iteration 538 , Loss: 5.655473709106445\n",
      "Iteration 539 , Loss: 3.9369640350341797\n",
      "Iteration 540 , Loss: 4.937779426574707\n",
      "Iteration 541 , Loss: 4.704017639160156\n",
      "Iteration 542 , Loss: 4.984401702880859\n",
      "Iteration 543 , Loss: 5.715011119842529\n",
      "Iteration 544 , Loss: 4.139510631561279\n",
      "Iteration 545 , Loss: 5.360528945922852\n",
      "Iteration 546 , Loss: 3.7664215564727783\n",
      "Iteration 547 , Loss: 4.675992488861084\n",
      "Iteration 548 , Loss: 4.730900764465332\n",
      "Iteration 549 , Loss: 4.510773658752441\n",
      "Iteration 550 , Loss: 4.86653470993042\n",
      "Iteration 551 , Loss: 5.067493915557861\n",
      "Iteration 552 , Loss: 4.377724647521973\n",
      "Iteration 553 , Loss: 4.630021572113037\n",
      "Iteration 554 , Loss: 4.69053840637207\n",
      "Iteration 555 , Loss: 4.629631996154785\n",
      "Iteration 556 , Loss: 4.299549102783203\n",
      "Iteration 557 , Loss: 5.085686206817627\n",
      "Iteration 558 , Loss: 4.785181522369385\n",
      "Iteration 559 , Loss: 4.645318984985352\n",
      "Iteration 560 , Loss: 3.704266309738159\n",
      "Iteration 561 , Loss: 3.9636662006378174\n",
      "Iteration 562 , Loss: 4.838873386383057\n",
      "Iteration 563 , Loss: 4.371397018432617\n",
      "Iteration 564 , Loss: 4.390899181365967\n",
      "Iteration 565 , Loss: 5.516741752624512\n",
      "Iteration 566 , Loss: 5.066842555999756\n",
      "Iteration 567 , Loss: 4.682256698608398\n",
      "Iteration 568 , Loss: 4.591091156005859\n",
      "Iteration 569 , Loss: 4.185582160949707\n",
      "Iteration 570 , Loss: 4.889713287353516\n",
      "Iteration 571 , Loss: 3.8121137619018555\n",
      "Iteration 572 , Loss: 5.488317012786865\n",
      "Iteration 573 , Loss: 4.949303150177002\n",
      "Iteration 574 , Loss: 3.91308856010437\n",
      "Iteration 575 , Loss: 5.342698574066162\n",
      "Iteration 576 , Loss: 4.202471733093262\n",
      "Iteration 577 , Loss: 4.034377574920654\n",
      "Iteration 578 , Loss: 3.014801502227783\n",
      "Iteration 579 , Loss: 4.869640350341797\n",
      "Iteration 580 , Loss: 4.24565315246582\n",
      "Iteration 581 , Loss: 5.311408042907715\n",
      "Iteration 582 , Loss: 3.8955249786376953\n",
      "Iteration 583 , Loss: 5.3828253746032715\n",
      "Iteration 584 , Loss: 5.266299724578857\n",
      "Iteration 585 , Loss: 4.406799793243408\n",
      "Iteration 586 , Loss: 4.42087459564209\n",
      "Iteration 587 , Loss: 4.035305023193359\n",
      "Iteration 588 , Loss: 4.675940990447998\n",
      "Iteration 589 , Loss: 4.474603176116943\n",
      "Iteration 590 , Loss: 4.340802192687988\n",
      "Iteration 591 , Loss: 3.585928440093994\n",
      "Iteration 592 , Loss: 4.356431007385254\n",
      "Iteration 593 , Loss: 4.08242130279541\n",
      "Iteration 594 , Loss: 3.49895977973938\n",
      "Iteration 595 , Loss: 4.76902437210083\n",
      "Iteration 596 , Loss: 4.6880412101745605\n",
      "Iteration 597 , Loss: 4.499572277069092\n",
      "Iteration 598 , Loss: 3.3125417232513428\n",
      "Iteration 599 , Loss: 5.004515171051025\n",
      "Iteration 600 , Loss: 3.6523404121398926\n",
      "Iteration 601 , Loss: 4.24899959564209\n",
      "Iteration 602 , Loss: 3.5891904830932617\n",
      "Iteration 603 , Loss: 3.767616033554077\n",
      "Iteration 604 , Loss: 4.303555965423584\n",
      "Iteration 605 , Loss: 4.778909683227539\n",
      "Iteration 606 , Loss: 3.7396106719970703\n",
      "Iteration 607 , Loss: 4.881602764129639\n",
      "Iteration 608 , Loss: 3.582514524459839\n",
      "Iteration 609 , Loss: 3.5603861808776855\n",
      "Iteration 610 , Loss: 3.497248411178589\n",
      "Iteration 611 , Loss: 4.0752177238464355\n",
      "Iteration 612 , Loss: 4.194056987762451\n",
      "Iteration 613 , Loss: 3.5379157066345215\n",
      "Iteration 614 , Loss: 4.095177173614502\n",
      "Iteration 615 , Loss: 4.107005596160889\n",
      "Iteration 616 , Loss: 3.983800172805786\n",
      "Iteration 617 , Loss: 5.322512626647949\n",
      "Iteration 618 , Loss: 4.191440582275391\n",
      "Iteration 619 , Loss: 2.992260456085205\n",
      "Iteration 620 , Loss: 3.0920324325561523\n",
      "Iteration 621 , Loss: 4.471365928649902\n",
      "Iteration 622 , Loss: 3.932814836502075\n",
      "Iteration 623 , Loss: 4.791731834411621\n",
      "Iteration 624 , Loss: 3.7284090518951416\n",
      "Iteration 625 , Loss: 4.057899475097656\n",
      "Iteration 626 , Loss: 3.2570295333862305\n",
      "Iteration 627 , Loss: 3.983107566833496\n",
      "Iteration 628 , Loss: 4.111884593963623\n",
      "Iteration 629 , Loss: 3.837033987045288\n",
      "Iteration 630 , Loss: 3.5191826820373535\n",
      "Iteration 631 , Loss: 3.409191370010376\n",
      "Iteration 632 , Loss: 4.229681015014648\n",
      "Iteration 633 , Loss: 3.3595492839813232\n",
      "Iteration 634 , Loss: 3.8468081951141357\n",
      "Iteration 635 , Loss: 4.080255031585693\n",
      "Iteration 636 , Loss: 4.120164394378662\n",
      "Iteration 637 , Loss: 3.585256576538086\n",
      "Iteration 638 , Loss: 3.285513401031494\n",
      "Iteration 639 , Loss: 3.4363460540771484\n",
      "Iteration 640 , Loss: 4.192187309265137\n",
      "Iteration 641 , Loss: 3.674318313598633\n",
      "Iteration 642 , Loss: 3.181724786758423\n",
      "Iteration 643 , Loss: 4.089089393615723\n",
      "Iteration 644 , Loss: 3.3290483951568604\n",
      "Iteration 645 , Loss: 3.728184938430786\n",
      "Iteration 646 , Loss: 3.6106410026550293\n",
      "Iteration 647 , Loss: 3.989248275756836\n",
      "Iteration 648 , Loss: 3.775820732116699\n",
      "Iteration 649 , Loss: 3.758314371109009\n",
      "Iteration 650 , Loss: 2.989321231842041\n",
      "Iteration 651 , Loss: 2.9378390312194824\n",
      "Iteration 652 , Loss: 3.3980965614318848\n",
      "Iteration 653 , Loss: 3.0227155685424805\n",
      "Iteration 654 , Loss: 3.9011282920837402\n",
      "Iteration 655 , Loss: 3.3966562747955322\n",
      "Iteration 656 , Loss: 3.362278938293457\n",
      "Iteration 657 , Loss: 3.933298349380493\n",
      "Iteration 658 , Loss: 3.5125246047973633\n",
      "Iteration 659 , Loss: 3.2802538871765137\n",
      "Iteration 660 , Loss: 3.0015969276428223\n",
      "Iteration 661 , Loss: 3.30861234664917\n",
      "Iteration 662 , Loss: 2.8843185901641846\n",
      "Iteration 663 , Loss: 3.618723154067993\n",
      "Iteration 664 , Loss: 3.0537233352661133\n",
      "Iteration 665 , Loss: 3.9383106231689453\n",
      "Iteration 666 , Loss: 3.257308006286621\n",
      "Iteration 667 , Loss: 3.7653450965881348\n",
      "Iteration 668 , Loss: 3.278470993041992\n",
      "Iteration 669 , Loss: 4.486398220062256\n",
      "Iteration 670 , Loss: 3.1959331035614014\n",
      "Iteration 671 , Loss: 3.6217594146728516\n",
      "Iteration 672 , Loss: 3.1272308826446533\n",
      "Iteration 673 , Loss: 3.5873217582702637\n",
      "Iteration 674 , Loss: 3.6668241024017334\n",
      "Iteration 675 , Loss: 3.3812777996063232\n",
      "Iteration 676 , Loss: 3.175934314727783\n",
      "Iteration 677 , Loss: 3.519747734069824\n",
      "Iteration 678 , Loss: 4.2538251876831055\n",
      "Iteration 679 , Loss: 3.319605827331543\n",
      "Iteration 680 , Loss: 3.4312973022460938\n",
      "Iteration 681 , Loss: 3.1719000339508057\n",
      "Iteration 682 , Loss: 3.6308646202087402\n",
      "Iteration 683 , Loss: 3.9315149784088135\n",
      "Iteration 684 , Loss: 3.7319555282592773\n",
      "Iteration 685 , Loss: 3.458190679550171\n",
      "Iteration 686 , Loss: 2.880906581878662\n",
      "Iteration 687 , Loss: 3.7143070697784424\n",
      "Iteration 688 , Loss: 3.9597370624542236\n",
      "Iteration 689 , Loss: 3.3360307216644287\n",
      "Iteration 690 , Loss: 3.1053459644317627\n",
      "Iteration 691 , Loss: 3.2951395511627197\n",
      "Iteration 692 , Loss: 2.846196174621582\n",
      "Iteration 693 , Loss: 2.9823811054229736\n",
      "Iteration 694 , Loss: 3.1718192100524902\n",
      "Iteration 695 , Loss: 3.223782539367676\n",
      "Iteration 696 , Loss: 3.204526424407959\n",
      "Iteration 697 , Loss: 3.279101848602295\n",
      "Iteration 698 , Loss: 3.05496883392334\n",
      "Iteration 699 , Loss: 3.2913382053375244\n",
      "Iteration 700 , Loss: 3.4219114780426025\n",
      "Iteration 701 , Loss: 3.791069507598877\n",
      "Iteration 702 , Loss: 4.759895324707031\n",
      "Iteration 703 , Loss: 3.483473539352417\n",
      "Iteration 704 , Loss: 3.8426589965820312\n",
      "Iteration 705 , Loss: 4.272171974182129\n",
      "Iteration 706 , Loss: 2.8398427963256836\n",
      "Iteration 707 , Loss: 3.0135560035705566\n",
      "Iteration 708 , Loss: 2.705165386199951\n",
      "Iteration 709 , Loss: 3.1997244358062744\n",
      "Iteration 710 , Loss: 3.1512575149536133\n",
      "Iteration 711 , Loss: 4.56481409072876\n",
      "Iteration 712 , Loss: 3.4289581775665283\n",
      "Iteration 713 , Loss: 2.7703452110290527\n",
      "Iteration 714 , Loss: 2.84309983253479\n",
      "Iteration 715 , Loss: 3.6477532386779785\n",
      "Iteration 716 , Loss: 3.1985104084014893\n",
      "Iteration 717 , Loss: 3.159219980239868\n",
      "Iteration 718 , Loss: 3.666379690170288\n",
      "Iteration 719 , Loss: 3.7690188884735107\n",
      "Iteration 720 , Loss: 3.070024251937866\n",
      "Iteration 721 , Loss: 3.2410359382629395\n",
      "Iteration 722 , Loss: 3.4529199600219727\n",
      "Iteration 723 , Loss: 2.7373948097229004\n",
      "Iteration 724 , Loss: 3.3758974075317383\n",
      "Iteration 725 , Loss: 3.4185712337493896\n",
      "Iteration 726 , Loss: 3.4954075813293457\n",
      "Iteration 727 , Loss: 3.2065727710723877\n",
      "Iteration 728 , Loss: 3.9868366718292236\n",
      "Iteration 729 , Loss: 3.345454454421997\n",
      "Iteration 730 , Loss: 3.1341300010681152\n",
      "Iteration 731 , Loss: 3.208758592605591\n",
      "Iteration 732 , Loss: 3.1405012607574463\n",
      "Iteration 733 , Loss: 3.668041467666626\n",
      "Iteration 734 , Loss: 3.5168912410736084\n",
      "Iteration 735 , Loss: 3.243295669555664\n",
      "Iteration 736 , Loss: 3.04693603515625\n",
      "Iteration 737 , Loss: 3.0303096771240234\n",
      "Iteration 738 , Loss: 3.4197659492492676\n",
      "Iteration 739 , Loss: 4.074617385864258\n",
      "Iteration 740 , Loss: 3.8002796173095703\n",
      "Iteration 741 , Loss: 2.9292140007019043\n",
      "Iteration 742 , Loss: 2.8408777713775635\n",
      "Iteration 743 , Loss: 3.232189178466797\n",
      "Iteration 744 , Loss: 3.3308510780334473\n",
      "Iteration 745 , Loss: 3.326798915863037\n",
      "Iteration 746 , Loss: 3.441840648651123\n",
      "Iteration 747 , Loss: 3.657259225845337\n",
      "Iteration 748 , Loss: 3.129000663757324\n",
      "Iteration 749 , Loss: 3.3163297176361084\n",
      "Iteration 750 , Loss: 2.782644748687744\n",
      "Iteration 751 , Loss: 2.9484951496124268\n",
      "Iteration 752 , Loss: 3.2400436401367188\n",
      "Iteration 753 , Loss: 3.2073731422424316\n",
      "Iteration 754 , Loss: 2.711690664291382\n",
      "Iteration 755 , Loss: 2.9602410793304443\n",
      "Iteration 756 , Loss: 2.7859365940093994\n",
      "Iteration 757 , Loss: 3.1158366203308105\n",
      "Iteration 758 , Loss: 3.676905632019043\n",
      "Iteration 759 , Loss: 2.8741965293884277\n",
      "Iteration 760 , Loss: 3.945185899734497\n",
      "Iteration 761 , Loss: 3.1434593200683594\n",
      "Iteration 762 , Loss: 3.6162142753601074\n",
      "Iteration 763 , Loss: 3.3669707775115967\n",
      "Iteration 764 , Loss: 3.229203462600708\n",
      "Iteration 765 , Loss: 3.005960702896118\n",
      "Iteration 766 , Loss: 3.257875680923462\n",
      "Iteration 767 , Loss: 3.5553743839263916\n",
      "Iteration 768 , Loss: 3.4797611236572266\n",
      "Iteration 769 , Loss: 4.840979099273682\n",
      "Iteration 770 , Loss: 3.0732436180114746\n",
      "Iteration 771 , Loss: 3.1494927406311035\n",
      "Iteration 772 , Loss: 3.016347885131836\n",
      "Iteration 773 , Loss: 3.986823320388794\n",
      "Iteration 774 , Loss: 3.4575188159942627\n",
      "Iteration 775 , Loss: 3.563648223876953\n",
      "Iteration 776 , Loss: 3.216505765914917\n",
      "Iteration 777 , Loss: 3.6749439239501953\n",
      "Iteration 778 , Loss: 3.118074655532837\n",
      "Iteration 779 , Loss: 3.2967004776000977\n",
      "Iteration 780 , Loss: 4.19706916809082\n",
      "Iteration 781 , Loss: 3.4813873767852783\n",
      "Iteration 782 , Loss: 3.7419559955596924\n",
      "Iteration 783 , Loss: 3.1195361614227295\n",
      "Iteration 784 , Loss: 2.8992252349853516\n",
      "Iteration 785 , Loss: 3.023648738861084\n",
      "Iteration 786 , Loss: 2.755789279937744\n",
      "Iteration 787 , Loss: 3.5132768154144287\n",
      "Iteration 788 , Loss: 2.9266316890716553\n",
      "Iteration 789 , Loss: 2.8388731479644775\n",
      "Iteration 790 , Loss: 3.55509614944458\n",
      "Iteration 791 , Loss: 3.547457695007324\n",
      "Iteration 792 , Loss: 3.1356289386749268\n",
      "Iteration 793 , Loss: 3.6294567584991455\n",
      "Iteration 794 , Loss: 4.737882614135742\n",
      "Iteration 795 , Loss: 3.592369794845581\n",
      "Iteration 796 , Loss: 3.520988941192627\n",
      "Iteration 797 , Loss: 3.9446280002593994\n",
      "Iteration 798 , Loss: 3.400677442550659\n",
      "Iteration 799 , Loss: 3.169395923614502\n",
      "Iteration 800 , Loss: 3.226552724838257\n",
      "Iteration 801 , Loss: 3.657956600189209\n",
      "Iteration 802 , Loss: 3.783963203430176\n",
      "Iteration 803 , Loss: 3.294546127319336\n",
      "Iteration 804 , Loss: 3.8691976070404053\n",
      "Iteration 805 , Loss: 3.6186978816986084\n",
      "Iteration 806 , Loss: 3.483488082885742\n",
      "Iteration 807 , Loss: 2.7878386974334717\n",
      "Iteration 808 , Loss: 4.10385799407959\n",
      "Iteration 809 , Loss: 4.538110256195068\n",
      "Iteration 810 , Loss: 4.108743667602539\n",
      "Iteration 811 , Loss: 2.836505651473999\n",
      "Iteration 812 , Loss: 3.471337080001831\n",
      "Iteration 813 , Loss: 2.9622480869293213\n",
      "Iteration 814 , Loss: 4.049267768859863\n",
      "Iteration 815 , Loss: 3.4705677032470703\n",
      "Iteration 816 , Loss: 4.341573238372803\n",
      "Iteration 817 , Loss: 3.9653851985931396\n",
      "Iteration 818 , Loss: 4.149606227874756\n",
      "Iteration 819 , Loss: 4.192827224731445\n",
      "Iteration 820 , Loss: 4.615479469299316\n",
      "Iteration 821 , Loss: 3.529644250869751\n",
      "Iteration 822 , Loss: 3.560671806335449\n",
      "Iteration 823 , Loss: 3.3297922611236572\n",
      "Iteration 824 , Loss: 2.930654287338257\n",
      "Iteration 825 , Loss: 3.2579708099365234\n",
      "Iteration 826 , Loss: 4.556092739105225\n",
      "Iteration 827 , Loss: 4.995888710021973\n",
      "Iteration 828 , Loss: 3.9506518840789795\n",
      "Iteration 829 , Loss: 4.100174427032471\n",
      "Iteration 830 , Loss: 3.4382035732269287\n",
      "Iteration 831 , Loss: 4.118277072906494\n",
      "Iteration 832 , Loss: 3.750891923904419\n",
      "Iteration 833 , Loss: 3.577824115753174\n",
      "Iteration 834 , Loss: 3.4993860721588135\n",
      "Iteration 835 , Loss: 3.5319793224334717\n",
      "Iteration 836 , Loss: 4.359984397888184\n",
      "Iteration 837 , Loss: 4.196103096008301\n",
      "Iteration 838 , Loss: 2.953577995300293\n",
      "Iteration 839 , Loss: 3.043166399002075\n",
      "Iteration 840 , Loss: 4.173430442810059\n",
      "Iteration 841 , Loss: 4.177670478820801\n",
      "Iteration 842 , Loss: 3.5611159801483154\n",
      "Iteration 843 , Loss: 3.525900363922119\n",
      "Iteration 844 , Loss: 4.025728702545166\n",
      "Iteration 845 , Loss: 2.8714547157287598\n",
      "Iteration 846 , Loss: 3.364231824874878\n",
      "Iteration 847 , Loss: 3.059014320373535\n",
      "Iteration 848 , Loss: 3.690413475036621\n",
      "Iteration 849 , Loss: 3.8550093173980713\n",
      "Iteration 850 , Loss: 3.6562819480895996\n",
      "Iteration 851 , Loss: 3.3803818225860596\n",
      "Iteration 852 , Loss: 3.2395358085632324\n",
      "Iteration 853 , Loss: 3.2516021728515625\n",
      "Iteration 854 , Loss: 3.9988327026367188\n",
      "Iteration 855 , Loss: 4.036282539367676\n",
      "Iteration 856 , Loss: 3.644362688064575\n",
      "Iteration 857 , Loss: 5.125401496887207\n",
      "Iteration 858 , Loss: 3.9616849422454834\n",
      "Iteration 859 , Loss: 3.7600674629211426\n",
      "Iteration 860 , Loss: 4.597117900848389\n",
      "Iteration 861 , Loss: 4.59141731262207\n",
      "Iteration 862 , Loss: 3.709850549697876\n",
      "Iteration 863 , Loss: 4.130306243896484\n",
      "Iteration 864 , Loss: 3.903010606765747\n",
      "Iteration 865 , Loss: 4.436802864074707\n",
      "Iteration 866 , Loss: 4.644026756286621\n",
      "Iteration 867 , Loss: 4.51735782623291\n",
      "Iteration 868 , Loss: 3.9687414169311523\n",
      "Iteration 869 , Loss: 3.8463714122772217\n",
      "Iteration 870 , Loss: 4.005793571472168\n",
      "Iteration 871 , Loss: 3.7485222816467285\n",
      "Iteration 872 , Loss: 4.30116081237793\n",
      "Iteration 873 , Loss: 3.8346409797668457\n",
      "Iteration 874 , Loss: 4.237978458404541\n",
      "Iteration 875 , Loss: 4.563136100769043\n",
      "Iteration 876 , Loss: 4.611419200897217\n",
      "Iteration 877 , Loss: 3.8315930366516113\n",
      "Iteration 878 , Loss: 3.820526123046875\n",
      "Iteration 879 , Loss: 4.92231559753418\n",
      "Iteration 880 , Loss: 3.874566078186035\n",
      "Iteration 881 , Loss: 4.475516319274902\n",
      "Iteration 882 , Loss: 4.038108825683594\n",
      "Iteration 883 , Loss: 5.132956027984619\n",
      "Iteration 884 , Loss: 3.971374750137329\n",
      "Iteration 885 , Loss: 3.878920555114746\n",
      "Iteration 886 , Loss: 5.161342620849609\n",
      "Iteration 887 , Loss: 4.076282978057861\n",
      "Iteration 888 , Loss: 3.453554153442383\n",
      "Iteration 889 , Loss: 3.440164089202881\n",
      "Iteration 890 , Loss: 4.4029364585876465\n",
      "Iteration 891 , Loss: 3.5705018043518066\n",
      "Iteration 892 , Loss: 5.149306774139404\n",
      "Iteration 893 , Loss: 4.451903343200684\n",
      "Iteration 894 , Loss: 4.175825595855713\n",
      "Iteration 895 , Loss: 4.639228343963623\n",
      "Iteration 896 , Loss: 5.485296726226807\n",
      "Iteration 897 , Loss: 5.201563835144043\n",
      "Iteration 898 , Loss: 5.443788528442383\n",
      "Iteration 899 , Loss: 5.10197114944458\n",
      "Iteration 900 , Loss: 3.774141550064087\n",
      "Iteration 901 , Loss: 4.491085052490234\n",
      "Iteration 902 , Loss: 5.2299652099609375\n",
      "Iteration 903 , Loss: 4.686699867248535\n",
      "Iteration 904 , Loss: 4.657211780548096\n",
      "Iteration 905 , Loss: 5.165301322937012\n",
      "Iteration 906 , Loss: 4.001078128814697\n",
      "Iteration 907 , Loss: 5.9792938232421875\n",
      "Iteration 908 , Loss: 5.538646221160889\n",
      "Iteration 909 , Loss: 4.231250286102295\n",
      "Iteration 910 , Loss: 5.420172691345215\n",
      "Iteration 911 , Loss: 5.99493408203125\n",
      "Iteration 912 , Loss: 6.393420696258545\n",
      "Iteration 913 , Loss: 5.738763332366943\n",
      "Iteration 914 , Loss: 4.6605916023254395\n",
      "Iteration 915 , Loss: 5.629757404327393\n",
      "Iteration 916 , Loss: 4.380746841430664\n",
      "Iteration 917 , Loss: 4.297026634216309\n",
      "Iteration 918 , Loss: 4.482218265533447\n",
      "Iteration 919 , Loss: 4.333451747894287\n",
      "Iteration 920 , Loss: 6.2928595542907715\n",
      "Iteration 921 , Loss: 6.762732982635498\n",
      "Iteration 922 , Loss: 7.7555084228515625\n",
      "Iteration 923 , Loss: 6.2406206130981445\n",
      "Iteration 924 , Loss: 6.776294708251953\n",
      "Iteration 925 , Loss: 4.026978492736816\n",
      "Iteration 926 , Loss: 4.500514030456543\n",
      "Iteration 927 , Loss: 4.608006954193115\n",
      "Iteration 928 , Loss: 4.498013973236084\n",
      "Iteration 929 , Loss: 5.033153533935547\n",
      "Iteration 930 , Loss: 4.545365810394287\n",
      "Iteration 931 , Loss: 5.40645694732666\n",
      "Iteration 932 , Loss: 5.609373569488525\n",
      "Iteration 933 , Loss: 5.9578728675842285\n",
      "Iteration 934 , Loss: 4.028064727783203\n",
      "Iteration 935 , Loss: 4.643910884857178\n",
      "Iteration 936 , Loss: 5.200762748718262\n",
      "Iteration 937 , Loss: 4.849359512329102\n",
      "Iteration 938 , Loss: 3.7738595008850098\n",
      "Iteration 939 , Loss: 4.312727451324463\n",
      "Iteration 940 , Loss: 5.056712627410889\n",
      "Iteration 941 , Loss: 4.332810401916504\n",
      "Iteration 942 , Loss: 4.144098281860352\n",
      "Iteration 943 , Loss: 3.619436264038086\n",
      "Iteration 944 , Loss: 5.824569225311279\n",
      "Iteration 945 , Loss: 5.851316452026367\n",
      "Iteration 946 , Loss: 5.735630035400391\n",
      "Iteration 947 , Loss: 5.2135820388793945\n",
      "Iteration 948 , Loss: 5.591052055358887\n",
      "Iteration 949 , Loss: 4.948826789855957\n",
      "Iteration 950 , Loss: 5.089745044708252\n",
      "Iteration 951 , Loss: 5.689324378967285\n",
      "Iteration 952 , Loss: 5.3791608810424805\n",
      "Iteration 953 , Loss: 6.9804606437683105\n",
      "Iteration 954 , Loss: 5.94361686706543\n",
      "Iteration 955 , Loss: 5.9802775382995605\n",
      "Iteration 956 , Loss: 5.197981834411621\n",
      "Iteration 957 , Loss: 5.700727939605713\n",
      "Iteration 958 , Loss: 5.2148237228393555\n",
      "Iteration 959 , Loss: 6.032818794250488\n",
      "Iteration 960 , Loss: 6.469320297241211\n",
      "Iteration 961 , Loss: 6.088381767272949\n",
      "Iteration 962 , Loss: 5.124404430389404\n",
      "Iteration 963 , Loss: 5.410365581512451\n",
      "Iteration 964 , Loss: 7.613966941833496\n",
      "Iteration 965 , Loss: 6.730595111846924\n",
      "Iteration 966 , Loss: 5.121304512023926\n",
      "Iteration 967 , Loss: 6.648898601531982\n",
      "Iteration 968 , Loss: 5.993757247924805\n",
      "Iteration 969 , Loss: 6.467130661010742\n",
      "Iteration 970 , Loss: 8.603992462158203\n",
      "Iteration 971 , Loss: 6.566352367401123\n",
      "Iteration 972 , Loss: 6.89218282699585\n",
      "Iteration 973 , Loss: 6.4924187660217285\n",
      "Iteration 974 , Loss: 7.32975435256958\n",
      "Iteration 975 , Loss: 5.447484970092773\n",
      "Iteration 976 , Loss: 5.453798770904541\n",
      "Iteration 977 , Loss: 6.919001579284668\n",
      "Iteration 978 , Loss: 6.388054370880127\n",
      "Iteration 979 , Loss: 4.7803120613098145\n",
      "Iteration 980 , Loss: 5.712630271911621\n",
      "Iteration 981 , Loss: 7.2546892166137695\n",
      "Iteration 982 , Loss: 7.75703763961792\n",
      "Iteration 983 , Loss: 5.656428813934326\n",
      "Iteration 984 , Loss: 6.023542881011963\n",
      "Iteration 985 , Loss: 8.101128578186035\n",
      "Iteration 986 , Loss: 10.762984275817871\n",
      "Iteration 987 , Loss: 9.596631050109863\n",
      "Iteration 988 , Loss: 8.691816329956055\n",
      "Iteration 989 , Loss: 7.9738054275512695\n",
      "Iteration 990 , Loss: 8.874958992004395\n",
      "Iteration 991 , Loss: 8.417591094970703\n",
      "Iteration 992 , Loss: 8.64078426361084\n",
      "Iteration 993 , Loss: 8.62027645111084\n",
      "Iteration 994 , Loss: 6.993576526641846\n",
      "Iteration 995 , Loss: 7.889835357666016\n",
      "Iteration 996 , Loss: 10.772785186767578\n",
      "Iteration 997 , Loss: 7.7423415184021\n",
      "Iteration 998 , Loss: 10.515298843383789\n",
      "Iteration 999 , Loss: 7.717567443847656\n",
      "Iteration 1000 , Loss: 6.945610523223877\n"
     ]
    }
   ],
   "source": [
    "lri = []  # contains the exponent of learning rate\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[X[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Y[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Store learning rate and loss\n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n",
    "    \n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7af03036f010>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3762383460998535\n"
     ]
    }
   ],
   "source": [
    "# We find that the best loss is for learning rate exponent around -1.0, so we set lr = 10**-1.0 and we can run more steps.\n",
    "for i in range(10000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[X[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Y[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    # print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 10**-1.0\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Store learning rate and loss\n",
    "    # lri.append(lre[i])\n",
    "    # lossi.append(loss.item())\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.563948154449463\n"
     ]
    }
   ],
   "source": [
    "# Decaying the learning rate and running more steps\n",
    "for i in range(10000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Y[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    # print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 10**-2.0\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # Store learning rate and loss\n",
    "    # lri.append(lre[i])\n",
    "    # lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.437300443649292"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]  \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is already better than what we have achieved using the model based on our intuition (bigram model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding train, test and validation split to avoid overfitting\n",
    "- #### Train split is used to obtain the parameters, validation split for choosing the best hyperparameters, train split for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([183258, 3]) torch.Size([183258])\n",
      "torch.Size([22861, 3]) torch.Size([22861])\n",
      "torch.Size([22924, 3]) torch.Size([22924])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "def build_dataset(words):\n",
    "    block_size = 3\n",
    "    X, Y = [], []\n",
    "    for w in words:  \n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])  # Same as validation set\n",
    "Xte, Yte = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([183258, 3]), torch.Size([183258]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting parameters\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((6, 300), generator=g, requires_grad=True)\n",
    "b1 = torch.randn((300,), generator=g, requires_grad=True)\n",
    "W2 = torch.randn((300, 27), generator=g, requires_grad=True)\n",
    "b2 = torch.randn((27,), generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Loss: 19.796716690063477\n",
      "Iteration 2 , Loss: 18.367109298706055\n",
      "Iteration 3 , Loss: 18.128002166748047\n",
      "Iteration 4 , Loss: 16.520008087158203\n",
      "Iteration 5 , Loss: 15.858794212341309\n",
      "Iteration 6 , Loss: 15.133967399597168\n",
      "Iteration 7 , Loss: 15.796759605407715\n",
      "Iteration 8 , Loss: 15.036417961120605\n",
      "Iteration 9 , Loss: 14.380845069885254\n",
      "Iteration 10 , Loss: 13.066110610961914\n",
      "Iteration 11 , Loss: 12.96157455444336\n",
      "Iteration 12 , Loss: 13.60091495513916\n",
      "Iteration 13 , Loss: 13.810588836669922\n",
      "Iteration 14 , Loss: 13.782127380371094\n",
      "Iteration 15 , Loss: 12.475520133972168\n",
      "Iteration 16 , Loss: 13.584747314453125\n",
      "Iteration 17 , Loss: 12.48475456237793\n",
      "Iteration 18 , Loss: 11.417655944824219\n",
      "Iteration 19 , Loss: 12.844965934753418\n",
      "Iteration 20 , Loss: 12.340853691101074\n",
      "Iteration 21 , Loss: 13.998640060424805\n",
      "Iteration 22 , Loss: 13.150482177734375\n",
      "Iteration 23 , Loss: 12.71766471862793\n",
      "Iteration 24 , Loss: 11.8101806640625\n",
      "Iteration 25 , Loss: 13.099871635437012\n",
      "Iteration 26 , Loss: 11.995466232299805\n",
      "Iteration 27 , Loss: 11.617557525634766\n",
      "Iteration 28 , Loss: 12.445409774780273\n",
      "Iteration 29 , Loss: 11.97336483001709\n",
      "Iteration 30 , Loss: 12.01740550994873\n",
      "Iteration 31 , Loss: 11.930365562438965\n",
      "Iteration 32 , Loss: 12.138778686523438\n",
      "Iteration 33 , Loss: 11.360647201538086\n",
      "Iteration 34 , Loss: 11.050159454345703\n",
      "Iteration 35 , Loss: 11.36189079284668\n",
      "Iteration 36 , Loss: 11.161236763000488\n",
      "Iteration 37 , Loss: 11.032458305358887\n",
      "Iteration 38 , Loss: 10.031280517578125\n",
      "Iteration 39 , Loss: 8.805747985839844\n",
      "Iteration 40 , Loss: 11.19875717163086\n",
      "Iteration 41 , Loss: 10.114402770996094\n",
      "Iteration 42 , Loss: 10.648077011108398\n",
      "Iteration 43 , Loss: 10.289073944091797\n",
      "Iteration 44 , Loss: 11.799142837524414\n",
      "Iteration 45 , Loss: 10.852935791015625\n",
      "Iteration 46 , Loss: 9.24499797821045\n",
      "Iteration 47 , Loss: 10.525485038757324\n",
      "Iteration 48 , Loss: 9.932724952697754\n",
      "Iteration 49 , Loss: 9.885429382324219\n",
      "Iteration 50 , Loss: 9.875436782836914\n",
      "Iteration 51 , Loss: 8.787097930908203\n",
      "Iteration 52 , Loss: 9.593046188354492\n",
      "Iteration 53 , Loss: 10.253316879272461\n",
      "Iteration 54 , Loss: 11.610116004943848\n",
      "Iteration 55 , Loss: 9.210494041442871\n",
      "Iteration 56 , Loss: 9.119986534118652\n",
      "Iteration 57 , Loss: 9.630294799804688\n",
      "Iteration 58 , Loss: 8.468057632446289\n",
      "Iteration 59 , Loss: 10.403223037719727\n",
      "Iteration 60 , Loss: 9.264634132385254\n",
      "Iteration 61 , Loss: 8.665962219238281\n",
      "Iteration 62 , Loss: 9.180699348449707\n",
      "Iteration 63 , Loss: 9.191972732543945\n",
      "Iteration 64 , Loss: 8.71863842010498\n",
      "Iteration 65 , Loss: 9.817567825317383\n",
      "Iteration 66 , Loss: 9.305548667907715\n",
      "Iteration 67 , Loss: 9.748597145080566\n",
      "Iteration 68 , Loss: 8.29411506652832\n",
      "Iteration 69 , Loss: 9.168540954589844\n",
      "Iteration 70 , Loss: 9.54004192352295\n",
      "Iteration 71 , Loss: 8.944328308105469\n",
      "Iteration 72 , Loss: 7.579687118530273\n",
      "Iteration 73 , Loss: 9.803085327148438\n",
      "Iteration 74 , Loss: 7.806015491485596\n",
      "Iteration 75 , Loss: 8.586236000061035\n",
      "Iteration 76 , Loss: 8.460770606994629\n",
      "Iteration 77 , Loss: 8.501667022705078\n",
      "Iteration 78 , Loss: 8.275797843933105\n",
      "Iteration 79 , Loss: 8.365403175354004\n",
      "Iteration 80 , Loss: 8.661309242248535\n",
      "Iteration 81 , Loss: 8.249051094055176\n",
      "Iteration 82 , Loss: 7.581202030181885\n",
      "Iteration 83 , Loss: 8.33653736114502\n",
      "Iteration 84 , Loss: 7.996042251586914\n",
      "Iteration 85 , Loss: 6.8825297355651855\n",
      "Iteration 86 , Loss: 8.825380325317383\n",
      "Iteration 87 , Loss: 7.580045223236084\n",
      "Iteration 88 , Loss: 9.018915176391602\n",
      "Iteration 89 , Loss: 7.230809688568115\n",
      "Iteration 90 , Loss: 8.203238487243652\n",
      "Iteration 91 , Loss: 6.92344856262207\n",
      "Iteration 92 , Loss: 7.735024452209473\n",
      "Iteration 93 , Loss: 8.715065002441406\n",
      "Iteration 94 , Loss: 6.939384937286377\n",
      "Iteration 95 , Loss: 7.636957168579102\n",
      "Iteration 96 , Loss: 7.078183650970459\n",
      "Iteration 97 , Loss: 8.089101791381836\n",
      "Iteration 98 , Loss: 7.489268779754639\n",
      "Iteration 99 , Loss: 8.138041496276855\n",
      "Iteration 100 , Loss: 8.037333488464355\n",
      "Iteration 101 , Loss: 8.713356018066406\n",
      "Iteration 102 , Loss: 7.215548515319824\n",
      "Iteration 103 , Loss: 8.140271186828613\n",
      "Iteration 104 , Loss: 7.799764156341553\n",
      "Iteration 105 , Loss: 7.587986469268799\n",
      "Iteration 106 , Loss: 7.169979095458984\n",
      "Iteration 107 , Loss: 7.465980052947998\n",
      "Iteration 108 , Loss: 7.420458793640137\n",
      "Iteration 109 , Loss: 8.554428100585938\n",
      "Iteration 110 , Loss: 8.156527519226074\n",
      "Iteration 111 , Loss: 6.646219730377197\n",
      "Iteration 112 , Loss: 6.628456115722656\n",
      "Iteration 113 , Loss: 6.100419998168945\n",
      "Iteration 114 , Loss: 8.165776252746582\n",
      "Iteration 115 , Loss: 6.630616664886475\n",
      "Iteration 116 , Loss: 6.592205047607422\n",
      "Iteration 117 , Loss: 7.208393096923828\n",
      "Iteration 118 , Loss: 6.797880172729492\n",
      "Iteration 119 , Loss: 6.882230281829834\n",
      "Iteration 120 , Loss: 6.771479606628418\n",
      "Iteration 121 , Loss: 6.9145989418029785\n",
      "Iteration 122 , Loss: 6.237492084503174\n",
      "Iteration 123 , Loss: 7.112697124481201\n",
      "Iteration 124 , Loss: 7.319239616394043\n",
      "Iteration 125 , Loss: 6.838927268981934\n",
      "Iteration 126 , Loss: 6.585921287536621\n",
      "Iteration 127 , Loss: 7.507281303405762\n",
      "Iteration 128 , Loss: 7.067765235900879\n",
      "Iteration 129 , Loss: 7.098551273345947\n",
      "Iteration 130 , Loss: 6.472670078277588\n",
      "Iteration 131 , Loss: 5.881916522979736\n",
      "Iteration 132 , Loss: 5.840823650360107\n",
      "Iteration 133 , Loss: 6.453797817230225\n",
      "Iteration 134 , Loss: 6.7917399406433105\n",
      "Iteration 135 , Loss: 6.803191661834717\n",
      "Iteration 136 , Loss: 6.6586012840271\n",
      "Iteration 137 , Loss: 7.263432025909424\n",
      "Iteration 138 , Loss: 6.789731025695801\n",
      "Iteration 139 , Loss: 5.901689052581787\n",
      "Iteration 140 , Loss: 5.904359340667725\n",
      "Iteration 141 , Loss: 6.3071980476379395\n",
      "Iteration 142 , Loss: 5.965672969818115\n",
      "Iteration 143 , Loss: 6.250892639160156\n",
      "Iteration 144 , Loss: 5.661666393280029\n",
      "Iteration 145 , Loss: 5.948898792266846\n",
      "Iteration 146 , Loss: 6.6480512619018555\n",
      "Iteration 147 , Loss: 6.018463611602783\n",
      "Iteration 148 , Loss: 5.952037334442139\n",
      "Iteration 149 , Loss: 5.407288074493408\n",
      "Iteration 150 , Loss: 6.493271350860596\n",
      "Iteration 151 , Loss: 6.527836799621582\n",
      "Iteration 152 , Loss: 7.227420330047607\n",
      "Iteration 153 , Loss: 6.143252372741699\n",
      "Iteration 154 , Loss: 6.200429916381836\n",
      "Iteration 155 , Loss: 6.437016010284424\n",
      "Iteration 156 , Loss: 5.918449878692627\n",
      "Iteration 157 , Loss: 5.550122261047363\n",
      "Iteration 158 , Loss: 6.025166988372803\n",
      "Iteration 159 , Loss: 5.812164783477783\n",
      "Iteration 160 , Loss: 5.957299709320068\n",
      "Iteration 161 , Loss: 6.5286784172058105\n",
      "Iteration 162 , Loss: 6.467317581176758\n",
      "Iteration 163 , Loss: 5.539290428161621\n",
      "Iteration 164 , Loss: 6.906189441680908\n",
      "Iteration 165 , Loss: 6.358974933624268\n",
      "Iteration 166 , Loss: 5.5784783363342285\n",
      "Iteration 167 , Loss: 6.123714447021484\n",
      "Iteration 168 , Loss: 6.359513759613037\n",
      "Iteration 169 , Loss: 5.980889320373535\n",
      "Iteration 170 , Loss: 5.282325744628906\n",
      "Iteration 171 , Loss: 5.91785192489624\n",
      "Iteration 172 , Loss: 6.056557655334473\n",
      "Iteration 173 , Loss: 5.875701904296875\n",
      "Iteration 174 , Loss: 6.61877965927124\n",
      "Iteration 175 , Loss: 5.7568464279174805\n",
      "Iteration 176 , Loss: 6.052577495574951\n",
      "Iteration 177 , Loss: 6.1824951171875\n",
      "Iteration 178 , Loss: 6.210722923278809\n",
      "Iteration 179 , Loss: 6.012156963348389\n",
      "Iteration 180 , Loss: 5.403632640838623\n",
      "Iteration 181 , Loss: 6.585993766784668\n",
      "Iteration 182 , Loss: 5.422488689422607\n",
      "Iteration 183 , Loss: 5.634527683258057\n",
      "Iteration 184 , Loss: 5.34855318069458\n",
      "Iteration 185 , Loss: 6.03765344619751\n",
      "Iteration 186 , Loss: 5.184828281402588\n",
      "Iteration 187 , Loss: 5.926487922668457\n",
      "Iteration 188 , Loss: 5.967142581939697\n",
      "Iteration 189 , Loss: 5.826178550720215\n",
      "Iteration 190 , Loss: 5.2522807121276855\n",
      "Iteration 191 , Loss: 5.721762180328369\n",
      "Iteration 192 , Loss: 5.367875576019287\n",
      "Iteration 193 , Loss: 6.3201422691345215\n",
      "Iteration 194 , Loss: 5.113733768463135\n",
      "Iteration 195 , Loss: 5.511369228363037\n",
      "Iteration 196 , Loss: 5.92130184173584\n",
      "Iteration 197 , Loss: 4.931894302368164\n",
      "Iteration 198 , Loss: 5.2936177253723145\n",
      "Iteration 199 , Loss: 5.98095703125\n",
      "Iteration 200 , Loss: 5.172591686248779\n",
      "Iteration 201 , Loss: 5.381119251251221\n",
      "Iteration 202 , Loss: 4.7932233810424805\n",
      "Iteration 203 , Loss: 5.014509201049805\n",
      "Iteration 204 , Loss: 5.046710014343262\n",
      "Iteration 205 , Loss: 5.091503620147705\n",
      "Iteration 206 , Loss: 6.0408244132995605\n",
      "Iteration 207 , Loss: 5.035477161407471\n",
      "Iteration 208 , Loss: 5.604311943054199\n",
      "Iteration 209 , Loss: 4.984006881713867\n",
      "Iteration 210 , Loss: 5.935933589935303\n",
      "Iteration 211 , Loss: 5.289088249206543\n",
      "Iteration 212 , Loss: 4.976356506347656\n",
      "Iteration 213 , Loss: 5.521416187286377\n",
      "Iteration 214 , Loss: 5.021697998046875\n",
      "Iteration 215 , Loss: 5.353074073791504\n",
      "Iteration 216 , Loss: 5.353177547454834\n",
      "Iteration 217 , Loss: 5.292045593261719\n",
      "Iteration 218 , Loss: 5.1277337074279785\n",
      "Iteration 219 , Loss: 4.562761306762695\n",
      "Iteration 220 , Loss: 5.23183012008667\n",
      "Iteration 221 , Loss: 4.877181053161621\n",
      "Iteration 222 , Loss: 4.843698501586914\n",
      "Iteration 223 , Loss: 4.180513858795166\n",
      "Iteration 224 , Loss: 5.161423206329346\n",
      "Iteration 225 , Loss: 4.458484649658203\n",
      "Iteration 226 , Loss: 5.071655750274658\n",
      "Iteration 227 , Loss: 4.804561138153076\n",
      "Iteration 228 , Loss: 4.637956142425537\n",
      "Iteration 229 , Loss: 4.370577335357666\n",
      "Iteration 230 , Loss: 4.746353626251221\n",
      "Iteration 231 , Loss: 3.7965736389160156\n",
      "Iteration 232 , Loss: 4.621494770050049\n",
      "Iteration 233 , Loss: 4.54083251953125\n",
      "Iteration 234 , Loss: 4.701745510101318\n",
      "Iteration 235 , Loss: 4.856943130493164\n",
      "Iteration 236 , Loss: 3.9942679405212402\n",
      "Iteration 237 , Loss: 4.565572738647461\n",
      "Iteration 238 , Loss: 4.864017009735107\n",
      "Iteration 239 , Loss: 4.771861553192139\n",
      "Iteration 240 , Loss: 4.578318119049072\n",
      "Iteration 241 , Loss: 4.4342570304870605\n",
      "Iteration 242 , Loss: 4.520374774932861\n",
      "Iteration 243 , Loss: 4.23329496383667\n",
      "Iteration 244 , Loss: 4.8487114906311035\n",
      "Iteration 245 , Loss: 4.644205570220947\n",
      "Iteration 246 , Loss: 4.783386707305908\n",
      "Iteration 247 , Loss: 4.106757640838623\n",
      "Iteration 248 , Loss: 4.919249057769775\n",
      "Iteration 249 , Loss: 4.431366920471191\n",
      "Iteration 250 , Loss: 4.462827205657959\n",
      "Iteration 251 , Loss: 3.970040798187256\n",
      "Iteration 252 , Loss: 3.74310564994812\n",
      "Iteration 253 , Loss: 4.305832862854004\n",
      "Iteration 254 , Loss: 4.114221096038818\n",
      "Iteration 255 , Loss: 3.8383586406707764\n",
      "Iteration 256 , Loss: 4.154754161834717\n",
      "Iteration 257 , Loss: 4.238700866699219\n",
      "Iteration 258 , Loss: 3.8104193210601807\n",
      "Iteration 259 , Loss: 3.4787914752960205\n",
      "Iteration 260 , Loss: 4.60490608215332\n",
      "Iteration 261 , Loss: 4.0475053787231445\n",
      "Iteration 262 , Loss: 3.6831040382385254\n",
      "Iteration 263 , Loss: 3.885045051574707\n",
      "Iteration 264 , Loss: 3.898772954940796\n",
      "Iteration 265 , Loss: 4.010321617126465\n",
      "Iteration 266 , Loss: 4.303937911987305\n",
      "Iteration 267 , Loss: 3.5429441928863525\n",
      "Iteration 268 , Loss: 3.855560779571533\n",
      "Iteration 269 , Loss: 4.0197062492370605\n",
      "Iteration 270 , Loss: 3.7439157962799072\n",
      "Iteration 271 , Loss: 3.908928155899048\n",
      "Iteration 272 , Loss: 3.585015296936035\n",
      "Iteration 273 , Loss: 3.9161901473999023\n",
      "Iteration 274 , Loss: 3.6928837299346924\n",
      "Iteration 275 , Loss: 3.3691866397857666\n",
      "Iteration 276 , Loss: 4.251379013061523\n",
      "Iteration 277 , Loss: 3.4822371006011963\n",
      "Iteration 278 , Loss: 3.90452241897583\n",
      "Iteration 279 , Loss: 3.8570690155029297\n",
      "Iteration 280 , Loss: 3.697805881500244\n",
      "Iteration 281 , Loss: 3.708021402359009\n",
      "Iteration 282 , Loss: 3.6509501934051514\n",
      "Iteration 283 , Loss: 4.10910177230835\n",
      "Iteration 284 , Loss: 3.8424246311187744\n",
      "Iteration 285 , Loss: 3.626668930053711\n",
      "Iteration 286 , Loss: 4.0024213790893555\n",
      "Iteration 287 , Loss: 3.7263083457946777\n",
      "Iteration 288 , Loss: 3.595660924911499\n",
      "Iteration 289 , Loss: 3.424010992050171\n",
      "Iteration 290 , Loss: 3.634990930557251\n",
      "Iteration 291 , Loss: 3.4244918823242188\n",
      "Iteration 292 , Loss: 3.750765085220337\n",
      "Iteration 293 , Loss: 3.5279452800750732\n",
      "Iteration 294 , Loss: 3.830883264541626\n",
      "Iteration 295 , Loss: 4.032598972320557\n",
      "Iteration 296 , Loss: 3.4867122173309326\n",
      "Iteration 297 , Loss: 3.5970206260681152\n",
      "Iteration 298 , Loss: 3.6880087852478027\n",
      "Iteration 299 , Loss: 3.6775224208831787\n",
      "Iteration 300 , Loss: 3.8740298748016357\n",
      "Iteration 301 , Loss: 3.308326005935669\n",
      "Iteration 302 , Loss: 3.774425983428955\n",
      "Iteration 303 , Loss: 3.5461931228637695\n",
      "Iteration 304 , Loss: 3.2678072452545166\n",
      "Iteration 305 , Loss: 3.6167211532592773\n",
      "Iteration 306 , Loss: 3.3042986392974854\n",
      "Iteration 307 , Loss: 3.454014778137207\n",
      "Iteration 308 , Loss: 3.300457715988159\n",
      "Iteration 309 , Loss: 3.2026171684265137\n",
      "Iteration 310 , Loss: 3.481947660446167\n",
      "Iteration 311 , Loss: 3.6175119876861572\n",
      "Iteration 312 , Loss: 3.5225932598114014\n",
      "Iteration 313 , Loss: 4.058739185333252\n",
      "Iteration 314 , Loss: 3.42380952835083\n",
      "Iteration 315 , Loss: 3.4804933071136475\n",
      "Iteration 316 , Loss: 3.567023515701294\n",
      "Iteration 317 , Loss: 3.127444267272949\n",
      "Iteration 318 , Loss: 3.2218194007873535\n",
      "Iteration 319 , Loss: 3.5127623081207275\n",
      "Iteration 320 , Loss: 3.322861433029175\n",
      "Iteration 321 , Loss: 3.4916610717773438\n",
      "Iteration 322 , Loss: 4.063455104827881\n",
      "Iteration 323 , Loss: 3.3457863330841064\n",
      "Iteration 324 , Loss: 3.822277784347534\n",
      "Iteration 325 , Loss: 3.702582359313965\n",
      "Iteration 326 , Loss: 3.6046319007873535\n",
      "Iteration 327 , Loss: 3.899322271347046\n",
      "Iteration 328 , Loss: 3.7746005058288574\n",
      "Iteration 329 , Loss: 3.8188393115997314\n",
      "Iteration 330 , Loss: 3.6610851287841797\n",
      "Iteration 331 , Loss: 3.365077495574951\n",
      "Iteration 332 , Loss: 3.152740001678467\n",
      "Iteration 333 , Loss: 3.5716028213500977\n",
      "Iteration 334 , Loss: 3.304112672805786\n",
      "Iteration 335 , Loss: 3.5224392414093018\n",
      "Iteration 336 , Loss: 3.372232675552368\n",
      "Iteration 337 , Loss: 3.4476001262664795\n",
      "Iteration 338 , Loss: 3.482149362564087\n",
      "Iteration 339 , Loss: 3.205455780029297\n",
      "Iteration 340 , Loss: 3.498349189758301\n",
      "Iteration 341 , Loss: 3.3043529987335205\n",
      "Iteration 342 , Loss: 3.541044235229492\n",
      "Iteration 343 , Loss: 3.2874090671539307\n",
      "Iteration 344 , Loss: 3.2447876930236816\n",
      "Iteration 345 , Loss: 3.42649507522583\n",
      "Iteration 346 , Loss: 3.417813539505005\n",
      "Iteration 347 , Loss: 3.332655668258667\n",
      "Iteration 348 , Loss: 3.089775562286377\n",
      "Iteration 349 , Loss: 3.0416347980499268\n",
      "Iteration 350 , Loss: 3.1283464431762695\n",
      "Iteration 351 , Loss: 3.761619806289673\n",
      "Iteration 352 , Loss: 3.23699951171875\n",
      "Iteration 353 , Loss: 3.8299813270568848\n",
      "Iteration 354 , Loss: 3.331418514251709\n",
      "Iteration 355 , Loss: 3.4802515506744385\n",
      "Iteration 356 , Loss: 3.3846566677093506\n",
      "Iteration 357 , Loss: 3.787809371948242\n",
      "Iteration 358 , Loss: 3.36883807182312\n",
      "Iteration 359 , Loss: 3.551469326019287\n",
      "Iteration 360 , Loss: 3.2916808128356934\n",
      "Iteration 361 , Loss: 3.380140781402588\n",
      "Iteration 362 , Loss: 3.492509126663208\n",
      "Iteration 363 , Loss: 3.3031880855560303\n",
      "Iteration 364 , Loss: 3.6205155849456787\n",
      "Iteration 365 , Loss: 3.1934425830841064\n",
      "Iteration 366 , Loss: 3.3805253505706787\n",
      "Iteration 367 , Loss: 3.1155829429626465\n",
      "Iteration 368 , Loss: 3.2860300540924072\n",
      "Iteration 369 , Loss: 3.3432159423828125\n",
      "Iteration 370 , Loss: 3.1042933464050293\n",
      "Iteration 371 , Loss: 3.1846537590026855\n",
      "Iteration 372 , Loss: 3.111835241317749\n",
      "Iteration 373 , Loss: 3.3683557510375977\n",
      "Iteration 374 , Loss: 3.0521881580352783\n",
      "Iteration 375 , Loss: 3.066164970397949\n",
      "Iteration 376 , Loss: 3.3390958309173584\n",
      "Iteration 377 , Loss: 3.161457061767578\n",
      "Iteration 378 , Loss: 3.1011407375335693\n",
      "Iteration 379 , Loss: 3.6956615447998047\n",
      "Iteration 380 , Loss: 3.214482069015503\n",
      "Iteration 381 , Loss: 3.248746633529663\n",
      "Iteration 382 , Loss: 3.3813283443450928\n",
      "Iteration 383 , Loss: 2.9450931549072266\n",
      "Iteration 384 , Loss: 3.370662212371826\n",
      "Iteration 385 , Loss: 3.33386492729187\n",
      "Iteration 386 , Loss: 3.2171308994293213\n",
      "Iteration 387 , Loss: 3.5522565841674805\n",
      "Iteration 388 , Loss: 3.1118576526641846\n",
      "Iteration 389 , Loss: 3.2934987545013428\n",
      "Iteration 390 , Loss: 3.4390149116516113\n",
      "Iteration 391 , Loss: 3.074126958847046\n",
      "Iteration 392 , Loss: 3.6723434925079346\n",
      "Iteration 393 , Loss: 3.412773847579956\n",
      "Iteration 394 , Loss: 3.128263235092163\n",
      "Iteration 395 , Loss: 3.3049750328063965\n",
      "Iteration 396 , Loss: 3.4233438968658447\n",
      "Iteration 397 , Loss: 3.3218135833740234\n",
      "Iteration 398 , Loss: 3.2150611877441406\n",
      "Iteration 399 , Loss: 2.9113428592681885\n",
      "Iteration 400 , Loss: 2.9668967723846436\n",
      "Iteration 401 , Loss: 3.46138596534729\n",
      "Iteration 402 , Loss: 3.235907793045044\n",
      "Iteration 403 , Loss: 3.1454567909240723\n",
      "Iteration 404 , Loss: 3.1875433921813965\n",
      "Iteration 405 , Loss: 3.391650915145874\n",
      "Iteration 406 , Loss: 3.148697853088379\n",
      "Iteration 407 , Loss: 3.0665509700775146\n",
      "Iteration 408 , Loss: 3.1251933574676514\n",
      "Iteration 409 , Loss: 3.1639606952667236\n",
      "Iteration 410 , Loss: 3.3124608993530273\n",
      "Iteration 411 , Loss: 3.0729408264160156\n",
      "Iteration 412 , Loss: 3.0163180828094482\n",
      "Iteration 413 , Loss: 3.4000649452209473\n",
      "Iteration 414 , Loss: 3.3576953411102295\n",
      "Iteration 415 , Loss: 3.2744436264038086\n",
      "Iteration 416 , Loss: 3.2496190071105957\n",
      "Iteration 417 , Loss: 3.417440891265869\n",
      "Iteration 418 , Loss: 3.399371862411499\n",
      "Iteration 419 , Loss: 3.4221506118774414\n",
      "Iteration 420 , Loss: 3.1959307193756104\n",
      "Iteration 421 , Loss: 3.1325645446777344\n",
      "Iteration 422 , Loss: 3.278447151184082\n",
      "Iteration 423 , Loss: 3.374547004699707\n",
      "Iteration 424 , Loss: 3.238743543624878\n",
      "Iteration 425 , Loss: 3.4034459590911865\n",
      "Iteration 426 , Loss: 3.125840902328491\n",
      "Iteration 427 , Loss: 3.1365177631378174\n",
      "Iteration 428 , Loss: 3.099900960922241\n",
      "Iteration 429 , Loss: 3.341637134552002\n",
      "Iteration 430 , Loss: 3.257436990737915\n",
      "Iteration 431 , Loss: 3.6995761394500732\n",
      "Iteration 432 , Loss: 3.0727155208587646\n",
      "Iteration 433 , Loss: 3.022406578063965\n",
      "Iteration 434 , Loss: 3.048236131668091\n",
      "Iteration 435 , Loss: 3.176157236099243\n",
      "Iteration 436 , Loss: 3.2244064807891846\n",
      "Iteration 437 , Loss: 3.496270179748535\n",
      "Iteration 438 , Loss: 3.13100266456604\n",
      "Iteration 439 , Loss: 3.269186019897461\n",
      "Iteration 440 , Loss: 2.9859652519226074\n",
      "Iteration 441 , Loss: 3.029090404510498\n",
      "Iteration 442 , Loss: 3.298060417175293\n",
      "Iteration 443 , Loss: 3.27103590965271\n",
      "Iteration 444 , Loss: 3.0771236419677734\n",
      "Iteration 445 , Loss: 3.019786834716797\n",
      "Iteration 446 , Loss: 3.0359904766082764\n",
      "Iteration 447 , Loss: 3.0136682987213135\n",
      "Iteration 448 , Loss: 3.3137166500091553\n",
      "Iteration 449 , Loss: 3.5774319171905518\n",
      "Iteration 450 , Loss: 3.1390292644500732\n",
      "Iteration 451 , Loss: 3.2400143146514893\n",
      "Iteration 452 , Loss: 3.0620718002319336\n",
      "Iteration 453 , Loss: 3.1007802486419678\n",
      "Iteration 454 , Loss: 3.0467019081115723\n",
      "Iteration 455 , Loss: 3.2412586212158203\n",
      "Iteration 456 , Loss: 3.420259952545166\n",
      "Iteration 457 , Loss: 3.994746208190918\n",
      "Iteration 458 , Loss: 3.203986883163452\n",
      "Iteration 459 , Loss: 3.1655218601226807\n",
      "Iteration 460 , Loss: 3.2900779247283936\n",
      "Iteration 461 , Loss: 3.163712501525879\n",
      "Iteration 462 , Loss: 3.0852110385894775\n",
      "Iteration 463 , Loss: 3.238424777984619\n",
      "Iteration 464 , Loss: 3.2346084117889404\n",
      "Iteration 465 , Loss: 3.482367992401123\n",
      "Iteration 466 , Loss: 3.37465238571167\n",
      "Iteration 467 , Loss: 3.2322964668273926\n",
      "Iteration 468 , Loss: 3.10554575920105\n",
      "Iteration 469 , Loss: 3.05643892288208\n",
      "Iteration 470 , Loss: 3.1514811515808105\n",
      "Iteration 471 , Loss: 3.4340689182281494\n",
      "Iteration 472 , Loss: 3.2259249687194824\n",
      "Iteration 473 , Loss: 3.0387980937957764\n",
      "Iteration 474 , Loss: 2.998506784439087\n",
      "Iteration 475 , Loss: 3.043323278427124\n",
      "Iteration 476 , Loss: 3.0432894229888916\n",
      "Iteration 477 , Loss: 3.13189959526062\n",
      "Iteration 478 , Loss: 3.0919671058654785\n",
      "Iteration 479 , Loss: 3.0842742919921875\n",
      "Iteration 480 , Loss: 3.2737724781036377\n",
      "Iteration 481 , Loss: 3.168992280960083\n",
      "Iteration 482 , Loss: 3.2009072303771973\n",
      "Iteration 483 , Loss: 3.1872000694274902\n",
      "Iteration 484 , Loss: 2.967698574066162\n",
      "Iteration 485 , Loss: 3.394007444381714\n",
      "Iteration 486 , Loss: 3.0438849925994873\n",
      "Iteration 487 , Loss: 3.147966146469116\n",
      "Iteration 488 , Loss: 3.138575553894043\n",
      "Iteration 489 , Loss: 3.683851957321167\n",
      "Iteration 490 , Loss: 2.9570767879486084\n",
      "Iteration 491 , Loss: 3.02518367767334\n",
      "Iteration 492 , Loss: 2.844568967819214\n",
      "Iteration 493 , Loss: 2.7939469814300537\n",
      "Iteration 494 , Loss: 3.119601249694824\n",
      "Iteration 495 , Loss: 3.20157790184021\n",
      "Iteration 496 , Loss: 3.205965995788574\n",
      "Iteration 497 , Loss: 3.396085739135742\n",
      "Iteration 498 , Loss: 3.7081644535064697\n",
      "Iteration 499 , Loss: 3.6758458614349365\n",
      "Iteration 500 , Loss: 3.400430202484131\n",
      "Iteration 501 , Loss: 3.668853998184204\n",
      "Iteration 502 , Loss: 3.737225294113159\n",
      "Iteration 503 , Loss: 3.3034768104553223\n",
      "Iteration 504 , Loss: 3.018336057662964\n",
      "Iteration 505 , Loss: 3.3275980949401855\n",
      "Iteration 506 , Loss: 3.5854063034057617\n",
      "Iteration 507 , Loss: 3.285987615585327\n",
      "Iteration 508 , Loss: 3.0650925636291504\n",
      "Iteration 509 , Loss: 3.134134292602539\n",
      "Iteration 510 , Loss: 3.2815468311309814\n",
      "Iteration 511 , Loss: 3.3092827796936035\n",
      "Iteration 512 , Loss: 3.5821144580841064\n",
      "Iteration 513 , Loss: 3.2615933418273926\n",
      "Iteration 514 , Loss: 3.248241424560547\n",
      "Iteration 515 , Loss: 3.356642484664917\n",
      "Iteration 516 , Loss: 3.41768479347229\n",
      "Iteration 517 , Loss: 3.6851534843444824\n",
      "Iteration 518 , Loss: 3.5139033794403076\n",
      "Iteration 519 , Loss: 3.08412504196167\n",
      "Iteration 520 , Loss: 3.401484489440918\n",
      "Iteration 521 , Loss: 3.448948621749878\n",
      "Iteration 522 , Loss: 4.588135242462158\n",
      "Iteration 523 , Loss: 3.8593358993530273\n",
      "Iteration 524 , Loss: 3.831317186355591\n",
      "Iteration 525 , Loss: 4.461264610290527\n",
      "Iteration 526 , Loss: 4.456819534301758\n",
      "Iteration 527 , Loss: 4.611622333526611\n",
      "Iteration 528 , Loss: 3.8470027446746826\n",
      "Iteration 529 , Loss: 3.4033658504486084\n",
      "Iteration 530 , Loss: 3.397658109664917\n",
      "Iteration 531 , Loss: 3.3622918128967285\n",
      "Iteration 532 , Loss: 3.0788280963897705\n",
      "Iteration 533 , Loss: 3.3708243370056152\n",
      "Iteration 534 , Loss: 3.6441855430603027\n",
      "Iteration 535 , Loss: 3.7757253646850586\n",
      "Iteration 536 , Loss: 3.3905422687530518\n",
      "Iteration 537 , Loss: 3.015784740447998\n",
      "Iteration 538 , Loss: 2.8912291526794434\n",
      "Iteration 539 , Loss: 2.9768431186676025\n",
      "Iteration 540 , Loss: 3.053102970123291\n",
      "Iteration 541 , Loss: 3.255215644836426\n",
      "Iteration 542 , Loss: 3.6646573543548584\n",
      "Iteration 543 , Loss: 3.7458486557006836\n",
      "Iteration 544 , Loss: 3.4963109493255615\n",
      "Iteration 545 , Loss: 3.566675901412964\n",
      "Iteration 546 , Loss: 3.369049310684204\n",
      "Iteration 547 , Loss: 3.317546844482422\n",
      "Iteration 548 , Loss: 3.678340435028076\n",
      "Iteration 549 , Loss: 3.7800846099853516\n",
      "Iteration 550 , Loss: 3.359464645385742\n",
      "Iteration 551 , Loss: 3.5380423069000244\n",
      "Iteration 552 , Loss: 4.091932773590088\n",
      "Iteration 553 , Loss: 3.8492939472198486\n",
      "Iteration 554 , Loss: 3.3042962551116943\n",
      "Iteration 555 , Loss: 3.217198610305786\n",
      "Iteration 556 , Loss: 3.6867947578430176\n",
      "Iteration 557 , Loss: 3.3299076557159424\n",
      "Iteration 558 , Loss: 3.4993467330932617\n",
      "Iteration 559 , Loss: 3.7971279621124268\n",
      "Iteration 560 , Loss: 3.2890281677246094\n",
      "Iteration 561 , Loss: 3.4735262393951416\n",
      "Iteration 562 , Loss: 3.9583141803741455\n",
      "Iteration 563 , Loss: 3.8569657802581787\n",
      "Iteration 564 , Loss: 4.434289932250977\n",
      "Iteration 565 , Loss: 4.73411226272583\n",
      "Iteration 566 , Loss: 4.966938495635986\n",
      "Iteration 567 , Loss: 4.61667013168335\n",
      "Iteration 568 , Loss: 4.046367168426514\n",
      "Iteration 569 , Loss: 4.447019100189209\n",
      "Iteration 570 , Loss: 4.388145923614502\n",
      "Iteration 571 , Loss: 3.9180245399475098\n",
      "Iteration 572 , Loss: 5.23638916015625\n",
      "Iteration 573 , Loss: 4.24840784072876\n",
      "Iteration 574 , Loss: 3.613844633102417\n",
      "Iteration 575 , Loss: 3.6700897216796875\n",
      "Iteration 576 , Loss: 4.054403781890869\n",
      "Iteration 577 , Loss: 4.383266925811768\n",
      "Iteration 578 , Loss: 3.8120646476745605\n",
      "Iteration 579 , Loss: 4.0678277015686035\n",
      "Iteration 580 , Loss: 5.588135719299316\n",
      "Iteration 581 , Loss: 14.74222183227539\n",
      "Iteration 582 , Loss: 13.453106880187988\n",
      "Iteration 583 , Loss: 12.255694389343262\n",
      "Iteration 584 , Loss: 9.38810920715332\n",
      "Iteration 585 , Loss: 8.324795722961426\n",
      "Iteration 586 , Loss: 12.217561721801758\n",
      "Iteration 587 , Loss: 7.852013111114502\n",
      "Iteration 588 , Loss: 6.776217460632324\n",
      "Iteration 589 , Loss: 8.20279598236084\n",
      "Iteration 590 , Loss: 7.069845199584961\n",
      "Iteration 591 , Loss: 5.898035526275635\n",
      "Iteration 592 , Loss: 10.139030456542969\n",
      "Iteration 593 , Loss: 6.973750591278076\n",
      "Iteration 594 , Loss: 9.428366661071777\n",
      "Iteration 595 , Loss: 7.059277057647705\n",
      "Iteration 596 , Loss: 7.056621074676514\n",
      "Iteration 597 , Loss: 8.492385864257812\n",
      "Iteration 598 , Loss: 5.936766624450684\n",
      "Iteration 599 , Loss: 5.377012252807617\n",
      "Iteration 600 , Loss: 5.16225004196167\n",
      "Iteration 601 , Loss: 6.452393054962158\n",
      "Iteration 602 , Loss: 6.910338401794434\n",
      "Iteration 603 , Loss: 4.913443565368652\n",
      "Iteration 604 , Loss: 6.880417346954346\n",
      "Iteration 605 , Loss: 9.198060989379883\n",
      "Iteration 606 , Loss: 9.687172889709473\n",
      "Iteration 607 , Loss: 10.686729431152344\n",
      "Iteration 608 , Loss: 10.091303825378418\n",
      "Iteration 609 , Loss: 8.986361503601074\n",
      "Iteration 610 , Loss: 10.925739288330078\n",
      "Iteration 611 , Loss: 8.368935585021973\n",
      "Iteration 612 , Loss: 8.252738952636719\n",
      "Iteration 613 , Loss: 12.955172538757324\n",
      "Iteration 614 , Loss: 7.320895195007324\n",
      "Iteration 615 , Loss: 6.356244087219238\n",
      "Iteration 616 , Loss: 5.915948867797852\n",
      "Iteration 617 , Loss: 6.868637561798096\n",
      "Iteration 618 , Loss: 8.673369407653809\n",
      "Iteration 619 , Loss: 6.709829807281494\n",
      "Iteration 620 , Loss: 8.598615646362305\n",
      "Iteration 621 , Loss: 8.087959289550781\n",
      "Iteration 622 , Loss: 11.464676856994629\n",
      "Iteration 623 , Loss: 8.215075492858887\n",
      "Iteration 624 , Loss: 7.367499828338623\n",
      "Iteration 625 , Loss: 6.944990158081055\n",
      "Iteration 626 , Loss: 7.6764068603515625\n",
      "Iteration 627 , Loss: 10.034863471984863\n",
      "Iteration 628 , Loss: 8.595555305480957\n",
      "Iteration 629 , Loss: 7.060684680938721\n",
      "Iteration 630 , Loss: 5.3794403076171875\n",
      "Iteration 631 , Loss: 6.1229448318481445\n",
      "Iteration 632 , Loss: 6.673434257507324\n",
      "Iteration 633 , Loss: 6.460517883300781\n",
      "Iteration 634 , Loss: 6.3242316246032715\n",
      "Iteration 635 , Loss: 6.249600410461426\n",
      "Iteration 636 , Loss: 8.251805305480957\n",
      "Iteration 637 , Loss: 9.332179069519043\n",
      "Iteration 638 , Loss: 7.835951805114746\n",
      "Iteration 639 , Loss: 8.716241836547852\n",
      "Iteration 640 , Loss: 7.753704071044922\n",
      "Iteration 641 , Loss: 11.761290550231934\n",
      "Iteration 642 , Loss: 10.137967109680176\n",
      "Iteration 643 , Loss: 9.218616485595703\n",
      "Iteration 644 , Loss: 6.99785041809082\n",
      "Iteration 645 , Loss: 5.769398212432861\n",
      "Iteration 646 , Loss: 4.964208602905273\n",
      "Iteration 647 , Loss: 4.5814337730407715\n",
      "Iteration 648 , Loss: 4.90299654006958\n",
      "Iteration 649 , Loss: 4.214603424072266\n",
      "Iteration 650 , Loss: 3.9909467697143555\n",
      "Iteration 651 , Loss: 3.9987545013427734\n",
      "Iteration 652 , Loss: 4.952629089355469\n",
      "Iteration 653 , Loss: 5.100718975067139\n",
      "Iteration 654 , Loss: 7.777678966522217\n",
      "Iteration 655 , Loss: 9.200728416442871\n",
      "Iteration 656 , Loss: 10.037202835083008\n",
      "Iteration 657 , Loss: 9.029380798339844\n",
      "Iteration 658 , Loss: 11.535676002502441\n",
      "Iteration 659 , Loss: 9.462949752807617\n",
      "Iteration 660 , Loss: 6.685250282287598\n",
      "Iteration 661 , Loss: 6.110569477081299\n",
      "Iteration 662 , Loss: 7.689795970916748\n",
      "Iteration 663 , Loss: 9.717459678649902\n",
      "Iteration 664 , Loss: 13.074956893920898\n",
      "Iteration 665 , Loss: 13.544637680053711\n",
      "Iteration 666 , Loss: 10.292389869689941\n",
      "Iteration 667 , Loss: 12.960277557373047\n",
      "Iteration 668 , Loss: 20.24289321899414\n",
      "Iteration 669 , Loss: 17.977298736572266\n",
      "Iteration 670 , Loss: 18.774694442749023\n",
      "Iteration 671 , Loss: 18.082571029663086\n",
      "Iteration 672 , Loss: 13.902331352233887\n",
      "Iteration 673 , Loss: 11.349017143249512\n",
      "Iteration 674 , Loss: 16.240991592407227\n",
      "Iteration 675 , Loss: 12.744071006774902\n",
      "Iteration 676 , Loss: 11.513118743896484\n",
      "Iteration 677 , Loss: 8.272485733032227\n",
      "Iteration 678 , Loss: 10.270071983337402\n",
      "Iteration 679 , Loss: 17.488290786743164\n",
      "Iteration 680 , Loss: 12.504765510559082\n",
      "Iteration 681 , Loss: 18.691177368164062\n",
      "Iteration 682 , Loss: 15.79877758026123\n",
      "Iteration 683 , Loss: 15.461274147033691\n",
      "Iteration 684 , Loss: 12.531270980834961\n",
      "Iteration 685 , Loss: 10.625861167907715\n",
      "Iteration 686 , Loss: 10.584628105163574\n",
      "Iteration 687 , Loss: 10.283943176269531\n",
      "Iteration 688 , Loss: 10.16594123840332\n",
      "Iteration 689 , Loss: 13.051919937133789\n",
      "Iteration 690 , Loss: 13.441805839538574\n",
      "Iteration 691 , Loss: 11.249356269836426\n",
      "Iteration 692 , Loss: 7.919459819793701\n",
      "Iteration 693 , Loss: 6.303918838500977\n",
      "Iteration 694 , Loss: 7.506424903869629\n",
      "Iteration 695 , Loss: 11.631369590759277\n",
      "Iteration 696 , Loss: 11.8198823928833\n",
      "Iteration 697 , Loss: 8.967802047729492\n",
      "Iteration 698 , Loss: 6.15830135345459\n",
      "Iteration 699 , Loss: 5.048389911651611\n",
      "Iteration 700 , Loss: 5.159870624542236\n",
      "Iteration 701 , Loss: 5.388392448425293\n",
      "Iteration 702 , Loss: 7.471466064453125\n",
      "Iteration 703 , Loss: 5.772606372833252\n",
      "Iteration 704 , Loss: 5.157276630401611\n",
      "Iteration 705 , Loss: 4.504749298095703\n",
      "Iteration 706 , Loss: 3.5008437633514404\n",
      "Iteration 707 , Loss: 5.542283535003662\n",
      "Iteration 708 , Loss: 5.930629730224609\n",
      "Iteration 709 , Loss: 4.514003753662109\n",
      "Iteration 710 , Loss: 6.054136276245117\n",
      "Iteration 711 , Loss: 6.141271591186523\n",
      "Iteration 712 , Loss: 4.528101444244385\n",
      "Iteration 713 , Loss: 5.7088541984558105\n",
      "Iteration 714 , Loss: 12.05683708190918\n",
      "Iteration 715 , Loss: 12.276063919067383\n",
      "Iteration 716 , Loss: 11.451563835144043\n",
      "Iteration 717 , Loss: 7.795659065246582\n",
      "Iteration 718 , Loss: 5.855825424194336\n",
      "Iteration 719 , Loss: 7.777313232421875\n",
      "Iteration 720 , Loss: 5.522778511047363\n",
      "Iteration 721 , Loss: 5.212477207183838\n",
      "Iteration 722 , Loss: 7.821108818054199\n",
      "Iteration 723 , Loss: 9.081493377685547\n",
      "Iteration 724 , Loss: 9.018966674804688\n",
      "Iteration 725 , Loss: 8.478068351745605\n",
      "Iteration 726 , Loss: 11.2407808303833\n",
      "Iteration 727 , Loss: 9.153697967529297\n",
      "Iteration 728 , Loss: 11.958823204040527\n",
      "Iteration 729 , Loss: 11.842456817626953\n",
      "Iteration 730 , Loss: 11.225223541259766\n",
      "Iteration 731 , Loss: 11.282196998596191\n",
      "Iteration 732 , Loss: 9.462312698364258\n",
      "Iteration 733 , Loss: 8.84976863861084\n",
      "Iteration 734 , Loss: 11.641206741333008\n",
      "Iteration 735 , Loss: 13.142769813537598\n",
      "Iteration 736 , Loss: 9.278203964233398\n",
      "Iteration 737 , Loss: 6.523931980133057\n",
      "Iteration 738 , Loss: 6.856594562530518\n",
      "Iteration 739 , Loss: 10.189535140991211\n",
      "Iteration 740 , Loss: 11.915517807006836\n",
      "Iteration 741 , Loss: 11.553057670593262\n",
      "Iteration 742 , Loss: 9.028042793273926\n",
      "Iteration 743 , Loss: 7.777608871459961\n",
      "Iteration 744 , Loss: 5.924105644226074\n",
      "Iteration 745 , Loss: 13.4922513961792\n",
      "Iteration 746 , Loss: 13.480388641357422\n",
      "Iteration 747 , Loss: 13.014385223388672\n",
      "Iteration 748 , Loss: 11.294489860534668\n",
      "Iteration 749 , Loss: 11.123873710632324\n",
      "Iteration 750 , Loss: 6.355742931365967\n",
      "Iteration 751 , Loss: 10.661227226257324\n",
      "Iteration 752 , Loss: 16.391826629638672\n",
      "Iteration 753 , Loss: 16.697650909423828\n",
      "Iteration 754 , Loss: 12.333806037902832\n",
      "Iteration 755 , Loss: 9.00633430480957\n",
      "Iteration 756 , Loss: 6.428811550140381\n",
      "Iteration 757 , Loss: 7.370483875274658\n",
      "Iteration 758 , Loss: 18.128328323364258\n",
      "Iteration 759 , Loss: 15.973939895629883\n",
      "Iteration 760 , Loss: 14.182229042053223\n",
      "Iteration 761 , Loss: 14.0873441696167\n",
      "Iteration 762 , Loss: 12.634750366210938\n",
      "Iteration 763 , Loss: 12.965505599975586\n",
      "Iteration 764 , Loss: 14.210622787475586\n",
      "Iteration 765 , Loss: 16.26816177368164\n",
      "Iteration 766 , Loss: 17.472341537475586\n",
      "Iteration 767 , Loss: 14.951152801513672\n",
      "Iteration 768 , Loss: 12.429045677185059\n",
      "Iteration 769 , Loss: 10.054041862487793\n",
      "Iteration 770 , Loss: 7.390407562255859\n",
      "Iteration 771 , Loss: 9.501875877380371\n",
      "Iteration 772 , Loss: 13.316513061523438\n",
      "Iteration 773 , Loss: 10.193948745727539\n",
      "Iteration 774 , Loss: 9.405770301818848\n",
      "Iteration 775 , Loss: 12.385169982910156\n",
      "Iteration 776 , Loss: 15.998307228088379\n",
      "Iteration 777 , Loss: 16.043500900268555\n",
      "Iteration 778 , Loss: 11.985785484313965\n",
      "Iteration 779 , Loss: 9.02573013305664\n",
      "Iteration 780 , Loss: 11.530041694641113\n",
      "Iteration 781 , Loss: 19.886899948120117\n",
      "Iteration 782 , Loss: 20.707555770874023\n",
      "Iteration 783 , Loss: 20.676820755004883\n",
      "Iteration 784 , Loss: 18.430191040039062\n",
      "Iteration 785 , Loss: 16.036720275878906\n",
      "Iteration 786 , Loss: 17.04305648803711\n",
      "Iteration 787 , Loss: 20.88688850402832\n",
      "Iteration 788 , Loss: 19.790990829467773\n",
      "Iteration 789 , Loss: 23.585710525512695\n",
      "Iteration 790 , Loss: 19.832279205322266\n",
      "Iteration 791 , Loss: 16.755834579467773\n",
      "Iteration 792 , Loss: 17.46857261657715\n",
      "Iteration 793 , Loss: 24.40823745727539\n",
      "Iteration 794 , Loss: 30.637409210205078\n",
      "Iteration 795 , Loss: 52.71021270751953\n",
      "Iteration 796 , Loss: 51.15388488769531\n",
      "Iteration 797 , Loss: 43.14341735839844\n",
      "Iteration 798 , Loss: 35.47787857055664\n",
      "Iteration 799 , Loss: 36.97711181640625\n",
      "Iteration 800 , Loss: 21.703821182250977\n",
      "Iteration 801 , Loss: 24.519407272338867\n",
      "Iteration 802 , Loss: 25.663619995117188\n",
      "Iteration 803 , Loss: 24.89842414855957\n",
      "Iteration 804 , Loss: 29.610925674438477\n",
      "Iteration 805 , Loss: 28.732160568237305\n",
      "Iteration 806 , Loss: 34.43161392211914\n",
      "Iteration 807 , Loss: 26.953834533691406\n",
      "Iteration 808 , Loss: 33.92317581176758\n",
      "Iteration 809 , Loss: 30.309091567993164\n",
      "Iteration 810 , Loss: 29.4362735748291\n",
      "Iteration 811 , Loss: 34.342811584472656\n",
      "Iteration 812 , Loss: 24.289005279541016\n",
      "Iteration 813 , Loss: 31.92832374572754\n",
      "Iteration 814 , Loss: 25.735305786132812\n",
      "Iteration 815 , Loss: 23.775968551635742\n",
      "Iteration 816 , Loss: 30.481388092041016\n",
      "Iteration 817 , Loss: 24.90016746520996\n",
      "Iteration 818 , Loss: 33.13945770263672\n",
      "Iteration 819 , Loss: 28.457820892333984\n",
      "Iteration 820 , Loss: 29.14486312866211\n",
      "Iteration 821 , Loss: 32.63543701171875\n",
      "Iteration 822 , Loss: 34.37746047973633\n",
      "Iteration 823 , Loss: 26.611896514892578\n",
      "Iteration 824 , Loss: 24.476308822631836\n",
      "Iteration 825 , Loss: 26.581113815307617\n",
      "Iteration 826 , Loss: 31.591123580932617\n",
      "Iteration 827 , Loss: 27.99820327758789\n",
      "Iteration 828 , Loss: 20.581758499145508\n",
      "Iteration 829 , Loss: 34.64616012573242\n",
      "Iteration 830 , Loss: 35.64507293701172\n",
      "Iteration 831 , Loss: 26.787521362304688\n",
      "Iteration 832 , Loss: 22.51352310180664\n",
      "Iteration 833 , Loss: 24.78517723083496\n",
      "Iteration 834 , Loss: 23.746198654174805\n",
      "Iteration 835 , Loss: 42.54413986206055\n",
      "Iteration 836 , Loss: 39.86234664916992\n",
      "Iteration 837 , Loss: 35.301048278808594\n",
      "Iteration 838 , Loss: 29.872352600097656\n",
      "Iteration 839 , Loss: 24.310274124145508\n",
      "Iteration 840 , Loss: 23.53718376159668\n",
      "Iteration 841 , Loss: 32.27479553222656\n",
      "Iteration 842 , Loss: 34.56242370605469\n",
      "Iteration 843 , Loss: 30.115955352783203\n",
      "Iteration 844 , Loss: 24.585046768188477\n",
      "Iteration 845 , Loss: 19.826961517333984\n",
      "Iteration 846 , Loss: 24.388399124145508\n",
      "Iteration 847 , Loss: 28.12273597717285\n",
      "Iteration 848 , Loss: 26.169044494628906\n",
      "Iteration 849 , Loss: 24.254013061523438\n",
      "Iteration 850 , Loss: 17.740114212036133\n",
      "Iteration 851 , Loss: 18.66822052001953\n",
      "Iteration 852 , Loss: 31.35000991821289\n",
      "Iteration 853 , Loss: 33.96097946166992\n",
      "Iteration 854 , Loss: 32.71505355834961\n",
      "Iteration 855 , Loss: 43.35919952392578\n",
      "Iteration 856 , Loss: 36.450008392333984\n",
      "Iteration 857 , Loss: 42.48282241821289\n",
      "Iteration 858 , Loss: 50.38962173461914\n",
      "Iteration 859 , Loss: 40.678688049316406\n",
      "Iteration 860 , Loss: 33.313899993896484\n",
      "Iteration 861 , Loss: 29.439598083496094\n",
      "Iteration 862 , Loss: 37.30300521850586\n",
      "Iteration 863 , Loss: 31.876462936401367\n",
      "Iteration 864 , Loss: 36.81336212158203\n",
      "Iteration 865 , Loss: 36.7895622253418\n",
      "Iteration 866 , Loss: 38.91999053955078\n",
      "Iteration 867 , Loss: 38.59517288208008\n",
      "Iteration 868 , Loss: 37.662864685058594\n",
      "Iteration 869 , Loss: 39.555320739746094\n",
      "Iteration 870 , Loss: 36.372318267822266\n",
      "Iteration 871 , Loss: 45.247798919677734\n",
      "Iteration 872 , Loss: 44.68213653564453\n",
      "Iteration 873 , Loss: 35.139835357666016\n",
      "Iteration 874 , Loss: 33.58869934082031\n",
      "Iteration 875 , Loss: 35.22430419921875\n",
      "Iteration 876 , Loss: 48.49674987792969\n",
      "Iteration 877 , Loss: 47.571022033691406\n",
      "Iteration 878 , Loss: 44.78147506713867\n",
      "Iteration 879 , Loss: 39.41952133178711\n",
      "Iteration 880 , Loss: 41.8685188293457\n",
      "Iteration 881 , Loss: 37.202571868896484\n",
      "Iteration 882 , Loss: 48.62433624267578\n",
      "Iteration 883 , Loss: 49.30403518676758\n",
      "Iteration 884 , Loss: 53.22724914550781\n",
      "Iteration 885 , Loss: 56.02946853637695\n",
      "Iteration 886 , Loss: 57.922340393066406\n",
      "Iteration 887 , Loss: 50.940582275390625\n",
      "Iteration 888 , Loss: 32.262447357177734\n",
      "Iteration 889 , Loss: 22.78789710998535\n",
      "Iteration 890 , Loss: 26.5537166595459\n",
      "Iteration 891 , Loss: 45.50607681274414\n",
      "Iteration 892 , Loss: 47.46444320678711\n",
      "Iteration 893 , Loss: 51.83258056640625\n",
      "Iteration 894 , Loss: 57.1013069152832\n",
      "Iteration 895 , Loss: 48.979835510253906\n",
      "Iteration 896 , Loss: 63.672264099121094\n",
      "Iteration 897 , Loss: 60.644596099853516\n",
      "Iteration 898 , Loss: 48.42068099975586\n",
      "Iteration 899 , Loss: 47.16435623168945\n",
      "Iteration 900 , Loss: 60.72992706298828\n",
      "Iteration 901 , Loss: 57.06806945800781\n",
      "Iteration 902 , Loss: 62.066287994384766\n",
      "Iteration 903 , Loss: 73.59716796875\n",
      "Iteration 904 , Loss: 65.62906646728516\n",
      "Iteration 905 , Loss: 58.69365310668945\n",
      "Iteration 906 , Loss: 56.00255584716797\n",
      "Iteration 907 , Loss: 46.95049285888672\n",
      "Iteration 908 , Loss: 55.06583786010742\n",
      "Iteration 909 , Loss: 85.77592468261719\n",
      "Iteration 910 , Loss: 94.9903793334961\n",
      "Iteration 911 , Loss: 83.59717559814453\n",
      "Iteration 912 , Loss: 80.158935546875\n",
      "Iteration 913 , Loss: 76.42723083496094\n",
      "Iteration 914 , Loss: 62.97441864013672\n",
      "Iteration 915 , Loss: 68.32542419433594\n",
      "Iteration 916 , Loss: 75.1322021484375\n",
      "Iteration 917 , Loss: 69.70172882080078\n",
      "Iteration 918 , Loss: 58.997554779052734\n",
      "Iteration 919 , Loss: 58.9361457824707\n",
      "Iteration 920 , Loss: 63.95310592651367\n",
      "Iteration 921 , Loss: 84.39569091796875\n",
      "Iteration 922 , Loss: 73.89830017089844\n",
      "Iteration 923 , Loss: 59.08808517456055\n",
      "Iteration 924 , Loss: 49.131103515625\n",
      "Iteration 925 , Loss: 63.95328903198242\n",
      "Iteration 926 , Loss: 79.12293243408203\n",
      "Iteration 927 , Loss: 74.30531311035156\n",
      "Iteration 928 , Loss: 59.12443161010742\n",
      "Iteration 929 , Loss: 66.75979614257812\n",
      "Iteration 930 , Loss: 56.89747619628906\n",
      "Iteration 931 , Loss: 56.05686950683594\n",
      "Iteration 932 , Loss: 68.30087280273438\n",
      "Iteration 933 , Loss: 53.67863845825195\n",
      "Iteration 934 , Loss: 69.21794891357422\n",
      "Iteration 935 , Loss: 86.66075134277344\n",
      "Iteration 936 , Loss: 81.04443359375\n",
      "Iteration 937 , Loss: 78.56929016113281\n",
      "Iteration 938 , Loss: 65.84184265136719\n",
      "Iteration 939 , Loss: 68.4137191772461\n",
      "Iteration 940 , Loss: 76.52045440673828\n",
      "Iteration 941 , Loss: 100.36290740966797\n",
      "Iteration 942 , Loss: 81.39965057373047\n",
      "Iteration 943 , Loss: 85.14315032958984\n",
      "Iteration 944 , Loss: 60.800174713134766\n",
      "Iteration 945 , Loss: 72.62495422363281\n",
      "Iteration 946 , Loss: 89.55956268310547\n",
      "Iteration 947 , Loss: 90.77176666259766\n",
      "Iteration 948 , Loss: 84.91410827636719\n",
      "Iteration 949 , Loss: 84.44850158691406\n",
      "Iteration 950 , Loss: 98.27226257324219\n",
      "Iteration 951 , Loss: 97.99691772460938\n",
      "Iteration 952 , Loss: 114.1346206665039\n",
      "Iteration 953 , Loss: 108.13802337646484\n",
      "Iteration 954 , Loss: 96.60958099365234\n",
      "Iteration 955 , Loss: 87.32878875732422\n",
      "Iteration 956 , Loss: 75.9677505493164\n",
      "Iteration 957 , Loss: 70.91175842285156\n",
      "Iteration 958 , Loss: 104.57453918457031\n",
      "Iteration 959 , Loss: 69.57845306396484\n",
      "Iteration 960 , Loss: 38.160911560058594\n",
      "Iteration 961 , Loss: 85.54800415039062\n",
      "Iteration 962 , Loss: 74.87385559082031\n",
      "Iteration 963 , Loss: 69.85306549072266\n",
      "Iteration 964 , Loss: 76.97496032714844\n",
      "Iteration 965 , Loss: 78.2717056274414\n",
      "Iteration 966 , Loss: 64.47616577148438\n",
      "Iteration 967 , Loss: 88.45101165771484\n",
      "Iteration 968 , Loss: 82.58322143554688\n",
      "Iteration 969 , Loss: 87.07022857666016\n",
      "Iteration 970 , Loss: 115.01839447021484\n",
      "Iteration 971 , Loss: 117.8646469116211\n",
      "Iteration 972 , Loss: 117.11228942871094\n",
      "Iteration 973 , Loss: 143.02223205566406\n",
      "Iteration 974 , Loss: 124.04658508300781\n",
      "Iteration 975 , Loss: 84.69124603271484\n",
      "Iteration 976 , Loss: 86.0996322631836\n",
      "Iteration 977 , Loss: 100.64823150634766\n",
      "Iteration 978 , Loss: 122.3802261352539\n",
      "Iteration 979 , Loss: 130.68777465820312\n",
      "Iteration 980 , Loss: 110.94316864013672\n",
      "Iteration 981 , Loss: 95.94609832763672\n",
      "Iteration 982 , Loss: 80.82185363769531\n",
      "Iteration 983 , Loss: 96.55072021484375\n",
      "Iteration 984 , Loss: 106.31703186035156\n",
      "Iteration 985 , Loss: 160.4967803955078\n",
      "Iteration 986 , Loss: 129.35435485839844\n",
      "Iteration 987 , Loss: 110.02238464355469\n",
      "Iteration 988 , Loss: 83.34439849853516\n",
      "Iteration 989 , Loss: 69.55103302001953\n",
      "Iteration 990 , Loss: 104.80375671386719\n",
      "Iteration 991 , Loss: 137.71385192871094\n",
      "Iteration 992 , Loss: 145.3173370361328\n",
      "Iteration 993 , Loss: 141.52642822265625\n",
      "Iteration 994 , Loss: 112.86764526367188\n",
      "Iteration 995 , Loss: 95.89871978759766\n",
      "Iteration 996 , Loss: 117.14765167236328\n",
      "Iteration 997 , Loss: 126.9778823852539\n",
      "Iteration 998 , Loss: 129.1268768310547\n",
      "Iteration 999 , Loss: 144.24044799804688\n",
      "Iteration 1000 , Loss: 177.67477416992188\n"
     ]
    }
   ],
   "source": [
    "lri = []  # contains the exponent of learning rate\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, Xdev.shape[0], (256,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[Xdev[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Ydev[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Store learning rate and loss\n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n",
    "    \n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7aef36b3fd60>]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8432483673095703\n"
     ]
    }
   ],
   "source": [
    "# We find that the best loss is for learning rate exponent around -1.4, so we set lr = 10**-1.4 and we can run more steps.\n",
    "lri = []\n",
    "stepi = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(10000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (256,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[Xtr[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Ytr[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    # print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 10**-4\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Store learning rate and loss\n",
    "    # lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.item())\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7aef3ea585e0>]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8290841579437256"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xte]  \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our dataset isn't very good, so the model isn't trained well in just 2 dimensions. We need to add more dimensions for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 10), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((30, 200), generator=g, requires_grad=True)\n",
    "b1 = torch.randn((200,), generator=g, requires_grad=True)\n",
    "W2 = torch.randn((200, 27), generator=g, requires_grad=True)\n",
    "b2 = torch.randn((27,), generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "lri = []\n",
    "stepi = []\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.982537031173706\n"
     ]
    }
   ],
   "source": [
    "# We find that the best loss is for learning rate exponent around -1.4, so we set lr = 10**-1.4 and we can run more steps.\n",
    "for i in range(50000):    \n",
    "    # Construct minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[Xtr[ix]]  # (32, 3, 10)\n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = prob[torch.arange(Y.shape[0]), Y].log().mean().neg()  # can be replaced by F.cross_entropy for softmax \n",
    "    loss = F.cross_entropy(logits, Ytr[ix])  # more efficient because it uses fused kernels, simplified expression during backpropagation\n",
    "    # print(\"Iteration\", i+1, \", Loss:\", loss.item())\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 10**-3\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Store learning rate and loss\n",
    "    # lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7aef367a7e50>]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8296139240264893"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xte]  \n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore-C1QhTUHj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
